[{"authors":["admin"],"categories":null,"content":"Soy un ingeniero de software con más de 10 años de experiencia en el sector. En todos estos años he pasado por diversas empresas ejerciendo distintos roles y he podido desarrollarme profesionalmente en distintas áreas.\nEste bagaje incluye el paso por grandes consultoras multinacionales, en las que he participado en diversos proyectos de distinta índole, he podido trabajar en proyectos en el extranjero integrándome en diferentes culturas, coordinar pequeños equipos de desarrollo, acompañar en los inicios a perfiles junior, formar parte de proyectos con multitud de equipos y numerosos, etc.\nTambién he tenido la ocasión de trabajar en una startup prácticamente desde el momento de su creación, lo cual me permitió experimentar lo difícil que es crear algo desde cero. Una experiencia muy valiosa que me permitió ver de cerca el otro lado de la moneda, el del empresario.\nMe apasiona la programación y tengo muchas inquietudes que me hacen estar en un aprendizaje continuo. Esto es lo que me ha llevado a estudiar un máster en Data Science \u0026amp; Big Data. Un área apasionante, con mucho que decir en los próximos años y del cual me gustaría formar parte en un futuro cercano.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"es","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://diegocastroviadero.com/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"Soy un ingeniero de software con más de 10 años de experiencia en el sector. En todos estos años he pasado por diversas empresas ejerciendo distintos roles y he podido desarrollarme profesionalmente en distintas áreas.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n \rParte I - Hardware \rParte II - Sistema Operativo y Docker Parte III - Cluster K3S Parte IV - (proximamente)  K3s \rK3s es una distribución de kubernetes certificada que ha sido concebida para el mundo IoT y \rEdge Computing. K3s ha sido optimizada para ARM (ARM64 y ARMv7) y esto es lo que ha hecho decidirme por esta distribución para instalar kubernetes en el cluster de raspberry pi. En K3s se han reducido las dependencias al máximo, haciendo posible que se distribuya como un único binario de menos de 40 MB. La reducción de dependencias también ha supuesto una simplificación del proceso de instalación.\nInstalación La instalación es muy sencilla, ya que el equipo de K3s ha creado un playbook de Ansible para realizarla. Yo me he basado en dicho playbook y he realizado alguna pequeña adaptación/mejora.\nLo primero que he realizado ha sido adaptar el fichero de inventario a las necesidades del playbook, para ello he definido los grupos:\n k3s_master: que incluye el nodo maestro k3s_node: que incluye los nodos esclavos k3s_cluster: que incluye todos los miembros del cluster  [k3s_master:children] rpicluster01 [k3s_node:children] rpicluster02 rpicluster03 rpicluster04 rpicluster05 [k3s_cluster:children] k3s_master k3s_node  (se puede ver el fichero completo aquí)\nA continuación se muestra el playbook de instalación:\n- hosts: k3s_cluster gather_facts: true become: true roles: - role: prereq - role: download - role: ubuntu - hosts: k3s_master become: true roles: - role: k3s/master - hosts: k3s_node become: true roles: - role: k3s/node  Como se puede observar, se basa en el uso de roles. Existen 3 roles de preparación (prereq, download y ubuntu) que se ejecutarán sobre todos los miembros del cluster. Estos roles se encargan de activar algunas configuraciones necesarias en el sistema operativo, así como de realizar la descarga del binario en función de la arquitectura sobre la que se esté realizando la instalación.\nAdemás existe un role que se ejecutará sobre el nodo maestro y otro que se ejecutará sobre los nodos esclavos. Estos roles son los que crean el cluster K3s propiamente dicho.\n(se puede ver el playbook completo aquí)\nConclusión Gracias al equipo de desarrollo de K3s, que nos proporciona un playbook de Ansible, se puede crear un cluster de kubernetes de una manera muy sencilla.\n","date":1602651600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1602694800,"objectID":"6b0ec67041bc26f66887535171d45038","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-iii/","publishdate":"2020-10-14T05:00:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-iii/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta tercera entrega explico cómo montar un cluster k3s.","tags":["cluster","raspberry","docker","k3s"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte III)","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n \rParte I - Hardware Parte II - Sistema Operativo y Docker \rParte III - Cluster K3S Parte IV - (proximamente)  Sistema Operativo Una vez que todo el hardware está montado la siguiente decisión a tomar es qué sistema operativo instalar en las Raspberry. En el momento de tomar la decisión barajaba 3 opciones:\n Raspbian Hypriot Ubuntu  Raspbian es la distribución oficial para raspberry, y sería una buena elección. Sin embargo, no me he decantado por esta opción, y la razón principal es que en el momento de tomar la decisión no había una versión final de 64 bits (estaba en beta).\nHypriot es una distribución que desconocía totalmente y que viene con docker preinstalado, lo cual simplificaría el proceso de instalación y supondría un ahorro de tiempo. Tampoco me he decidido por esta opción, y el motivo es el mismo que con Raspbian, no existe una versión de 64 bits.\nTras haber descartado las dos distribuciones anteriores me entró la duda de si mi idea inicial de instalar una distribución de 64 bits era una buena idea. Inicialmente pensaba que con una distribución de 32 bits no podría aprovechar los 8 GB de RAM de las raspberry y de ahí que buscase una distribución de 64 bits. Tras investigar un poco, me di cuenta de que esto no era cierto del todo, con una distribución de 32 bits sí que se aprovecharían los 8 GB de RAM. Un mismo proceso del sistema operativo podría usar como mucho 4 GB de RAM, pero entre varios procesos se podrían consumir los 8 GB. Aún así, mantuve mi idea inicial de instalar una distribución de 64 bits, creo que no tiene sentido a día de hoy comenzar un proyecto optando por 32 bits, aunque esta elección traiga ciertas \u0026ldquo;ventajas\u0026rdquo; inicialmente.\nFinalmente descubrí que Ubuntu tiene distribuciones para ARM y que estas pueden ser de 64 bits. Así que - \u0026ldquo;Señores, ¡Ya tenemos caballo ganador!\u0026rdquo;.\nCon el sistema operativo elegido lo siguiente era:\n flashear las 5 tarjetas de memoria actualizar y realizar ciertas configuraciones en las 5 raspberry instalar Docker en las 5 raspberry  En estos momentos me arrepentí un poco de haber comprado 5 raspberry porque todo lo que fuese a hacer lo tenía que repetir 5 veces. Si tienes claro el proceso, es cuestión de seguirlo a pies juntillas y repetirlo las veces que sea necesario. El problema viene cuando el proceso no está claramente definido, y con cada repetición se va refinando el mismo. Este \u0026ldquo;ir refinando el proceso a medida que lo vas repitiendo\u0026rdquo; no debería ser algo problemático. El problema radica en mi persona y mi obsesión con algunas cosas, y en este caso mi obsesión no me permitiría sentirme cómodo sabiendo que no he ejecutado el mismo proceso en todas las raspberry. Si cuando estoy en la última raspberry me doy cuenta de que sería mejor hacer algo de forma diferente, me vería obligado a volver a hacerlo en todas las raspberry. Aquí es donde la situación podría descontrolarse y llevarme muchísimo más tiempo del necesario con la única ventaja de tener todas las rapberry exactamente iguales.\nAntes de lanzarme a configurar las raspberry busqué la forma de automatizar todo el proceso de configuración, lo cual me permitiría dormir tranquilo sabiendo que todas las raspberry son almas gemelas sin tener que repetir manualmente el proceso de configuración por enésima vez sobre la oveja negra del rebaño. Y la búsqueda fue fructífera, me topé con Cloud-Init y con Ansible.\nCloud-Init Cloud-Init es una tecnología que permite inicializar una instancia y que viene de caja con Ubuntu. Cloud-Init detecta si es el primer arranque del sistema y si es el caso entra en acción permitiendo configurar: usuarios, claves ssh, particiones de disco, configuración de red, etc. Cloud-Init puede obtener las acciones que tiene que ejecutar del propio disco de la instacia o podría obtenerlo a través de la red.\nEn mi caso, las acciones a actualizar las obtiene del propio disco: una vez flasheada la tarjeta SD copio un par de ficheros en la tarjeta con las configuraciones a realizar. Concretamente utilizo cloud-init para:\n actualizar los paquetes del sistema establecer el nombre de la instancia configurar el DNS desactivar la creación del usuario por defecto del sistema operativo crear un usuario específico establecer una clave SSH para el usuario deshabilitar el acceso al sistema con contraseña configuración de una ip fija instalación de paquetes adicionales: curl, vim, git y aptitude  Este es un ejemplo de fichero de configuración de cloud-init de uno de los nodos del cluster:\n#cloud-config preserve_hostname: false hostname: rpicluster01 fqdn: rpicluster01.test package_update: true package_upgrade: true package_reboot_if_required: true manage_resolv_conf: true resolv_conf: nameservers: ['8.8.4.4', '8.8.8.8'] users: ## Disable creation of default user #- default ## Create user - name: rpicluster homedir: /home/rpicluster lock_passwd: true shell: /bin/bash # Generate key with command: ssh-keygen -t rsa -b 4096 -C \u0026quot;your_email@example.com\u0026quot; ssh_authorized_keys: - ************************************************************************************** sudo: - ALL=(ALL) NOPASSWD:ALL ## Disable password authentication with the SSH daemon ssh_pwauth: false ## Install additional packages on first boot packages: - curl - vim - git - aptitude final_message: \u0026quot;The system is finally up, after $UPTIME seconds\u0026quot;  La configuración de red se establece en otro fichero diferente que tiene la siguiente pinta:\n# This file contains a netplan-compatible configuration which cloud-init # will apply on first-boot. Please refer to the cloud-init documentation and # the netplan reference for full details: # # https://cloudinit.readthedocs.io/ # https://netplan.io/reference # # Some additional examples are commented out below version: 2 ethernets: eth0: dhcp4: false addresses: [192.168.86.51/24] gateway4: 192.168.86.1 mtu: 1500 nameservers: addresses: [8.8.4.4, 8.8.8.8] optional: true #wifis: # wlan0: # dhcp4: true # optional: true # access-points: # myhomewifi: # password: \u0026quot;S3kr1t\u0026quot; # myworkwifi: # password: \u0026quot;correct battery horse staple\u0026quot; # workssid: # auth: # key-management: eap # method: peap # identity: \u0026quot;me@example.com\u0026quot; # password: \u0026quot;passw0rd\u0026quot; # ca-certificate: /etc/my_ca.pem  Para flashear la imagen del sistema operativo en la tarjeta SD utilizo rpiimager. Esta herramienta te provee de una interfaz gráfica muy sencilla en la que en primer lugar se selecciona la imagen que quieres flashear, en segundo lugar se elige dónde la quieres flashear y por último se inicia la grabación. Esta herramienta te evita tener que descargar la imagen del sistema operativo ya que es la propia herramienta quien se encarga de descargarla.\nAl arrancar la raspberry por primera vez cloud-init se activará y ejecutará las acciones anteriores, lo único que hay que hacer es esperar unos minutos. Alguien perspicaz, se habrá dado cuenta que hay dos acciones en la lista anterior que no son iguales para todas las raspberry del cluster: establecer el nombre de la instancia y configurar una ip fija. Esto hace que haya que tener para cada instancia del cluster un fichero de configuración diferente. Y en este punto es donde entra en acción Ansible.\n Aunque se le asigne una ip fija a las raspberry, en el router habrá que reservarla igualmente, ya que podría darse el caso de que mientras está apagado el cluster, se conecte algún dispositivo a la red y se le asigne una de las ips del cluster.\n Ansible Ansible, resumiéndolo mucho, es una herramienta de automatización de tareas. Dado un fichero de inventario, en el que se definen una serie de máquinas; y un fichero de tareas (playbook), en el que se definen una serie de tareas; Ansible se encargará de ejecutar cada una de las tareas en cada una de las máquinas. Con el añadido de que la ejecución de dichas tareas es idempotente, es decir, que si alguna de las tareas ya se ha ejecutado en alguna de dichas máquinas, no la volverá a ejecutar. Esto es una simplificación muy grande de todo el universo de Ansible, pero en este post no quiero entrar en detalles sobre Ansible, sino en explicar lo mínimo para que se entienda de qué forma se ha utilizado esta herramienta para montar el cluster.\nComo he mencionado anteriormente, he utilizado Ansible para la generación de los ficheros de configuración de cloud-init. Y este es un caso de uso un poco especial, puesto que no se ajusta a la descripción anterior sobre el funcionamiento básico de Ansible. Sí que disponemos de un fichero de inventario, pero no utilizamos Ansible para ejecutar ninguna tarea sobre las máquinas del inventario, sino para obtener unos datos sobre dichas máquinas y utilizarlos para generar unos ficheros de configuración en el puesto local.\nEste es un extracto del fichero de inventario:\n[rpicluster01] 192.168.86.51 [rpicluster01:vars] custom_hostname=rpicluster01 [rpicluster02] 192.168.86.52 [rpicluster02:vars] custom_hostname=rpicluster02 [rpicluster03] 192.168.86.53 [rpicluster03:vars] custom_hostname=rpicluster03 [rpicluster04] 192.168.86.54 [rpicluster04:vars] custom_hostname=rpicluster04 [rpicluster05] 192.168.86.55 [rpicluster05:vars] custom_hostname=rpicluster05 [rpicluster:children] rpicluster01 rpicluster02 rpicluster03 rpicluster04 rpicluster05  En este caso hemos definido el inventario en un fichero en formato INI. Se puede ver que se han definido varios grupos. Hay un grupo con un solo elemento para cada una de las máquinas del cluster y así poder hacer referencia a una máquina concreta:\n rpicluster01 rpicluster02 rpicluster03 rpicluster04 rpicluster05  También hay un grupo que está compuesto por todas las máquinas del cluster, para poder hacer referencia a todo el cluster:\n rpicluster  Para cada una de las máquinas se define una propiedad custom_hostname que contiene el nombre de la máquina.\n(se puede ver el fichero completo aquí)\nA continuación se muestra el playbook de ansible que genera los ficheros de configuración de cloud-init para las máquinas del cluster:\n--- - hosts: rpicluster gather_facts: false tasks: - name: create directories file: path: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}\u0026quot; state: directory delegate_to: localhost - name: generate user-data config file from template template: src: template_userdata.j2 dest: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}/user-data\u0026quot; delegate_to: localhost - name: generate network-config file from template template: src: template_networkconfig.j2 dest: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}/network-config\u0026quot; delegate_to: localhost  Se definen 3 tareas:\n La tarea 1 se encarga de crear un directorio para cada una de las máquinas del inventario La tarea 2 genera el fichero de configuración user-data a partir de un template La tarea 3 genera el fichero de configuración network-config a partir de un template  (se puede ver el playbook completo aquí)\nDocker Gracias a Ansible, la instalación de Docker en todas las máquinas se ha simplificado al máximo. He encontrado un playbook, que he utilizado casi tal cual, que se encarga de instalar Docker en sistemas debian. Se puede encontrar la versión que he utilizado aquí.\nConclusión Como conclusión he de decir que tanto cloud-init como Ansible han sido dos grandes descubrimientos. Sobre todo Ansible, ya que veo que es una herramienta que puedo empezar a utilizar en mi día a día a nivel profesional.\nLa única pega que le veo a Ansible, es que algunos aspectos no son compatibles con Windows. Actualmente utilizo un Windows 10 y he podido hacer uso de Ansible sin grandes complicaciones a través de WLS. El único inconveniente que me he topado hasta el momento, ha sido a la hora de utilizar Ansible Vault, ya que para ciertas situaciones es necesario modificar los permisos de algunos ficheros, lo cual no es posible en WLS a día de hoy (o al menos yo no he encontrado la manera de hacerlo).\n","date":1601205540,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1602257160,"objectID":"5aa94f4c61de593b99b1deac7a6b87ae","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-ii/","publishdate":"2020-09-27T11:19:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-ii/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta segunda parte explico qué sistema operativo he decidido instalar en los nodos del cluster y cómo instalar Docker en los mismos.","tags":["cluster","raspberry","docker","ubuntu","ansible","cloud-init"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte II)","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n Parte I - Hardware \rParte II - Sistema Operativo y Docker \rParte III - Cluster K3S Parte IV - (proximamente)  Introducción Kubernetes es una tecnología de orquestación de contenedores que lleva en el mercado ya varios años. Sin embargo, hasta la fecha, no he tenido la oportunidad de \u0026ldquo;jugar\u0026rdquo; con ella. Llevo varios años trabajando intensamente con Docker, y tenía como asignatura pendiente empezar a utilizar algún orquestador de contenedores. Como a nivel profesional no he tenido la ocasión de hacerlo, y como pienso que como mejor se aprende es practicando, nada mejor para aprender Kubernetes, que montarme un cluster Kubernetes desde cero. Quizás llegue un poco tarde, pero creo que es mejor tarde que nunca.\nFinalmente me he decidido por montar un cluster on premise en mi casa. Al principio pensé que lo más sencillo, rápido y barato sería hacerlo en el cloud, pero lo cierto es que me daba mucha pereza. Demasiados proveedores, cada uno con unos servicios gratuitos, con unas condiciones de pago por uso diferentes, en alguno de los cuales ya había consumido dicho uso gratuito, etc.\nAunque montar un cluster on premise suponga un desembolso inicial superior y un mayor esfuerzo, frente a montarlo en el cloud, encuentro al menos dos motivos que han hecho que me decline por esta opción.\nEn primer lugar, considero que montando el cluster on premise me puede simplificar el aprendizaje de los conceptos básicos, ya que no me veré distraído por la terminología y servicios accesorios varios ofrecidos por los proveedores cloud.\nEn segundo lugar, me da mucha tranquilidad saber que si lo apago no consumo nada. Sé que este argumento puede no tener mucho sentido, ya que en el cloud, uno tiene control sobre los servicios que contrata y también podría \u0026ldquo;apagarlo\u0026rdquo; en cualquier momento. La cosa es que el mundo de los proveedores cloud también es nuevo para mí, y el sistema de facturación me parece un poco complejo. Sería otra cosa desconocida adicional a la que enfrentarme. Mi objetivo inicial es aprender Kubernetes, no es conocer como montar un cluster kubernetes en Amazon, Google o Azure y cuánto me van a cobrar por ello. En el pasado ya he tenido algún susto con grandes facturas de proveedores cloud, por creer que estaba haciendo uso de los servicios gratuitos, cuando no era cierto.\nComponentes El cluster está compuesto inicialmente de 5 Raspberry Pi modelo 4b con 8GB de RAM. Esto hace que el cluster disponga de:\n 20 cores a 1'5 GHz 40 GB de memoia RAM  Cada Raspberry tiene una tarjeta de memoria microSD Samsung EVO Plus de 32GB. Este almacenamiento será únicamente para la ejecución del sistema operativo. Inicialmente también lo utilizaré para la persistencia de los contenedores del cluster. Más adelante cuando me adentre en el mundo de los volúmenes persistentes, montaré un mecanismo de persistencia dedicado.\nCon el objetivo de facilizar el montaje del cluster y reducir el número de clables necesarios, he comprado unos módulos HAT PoE que me permiten alimentar las Raspberry por PoE. De esta forma puedo prescindir de los transformadores y los cables USB para alimentar las Raspberry, ya que con el mismo cable ethernet alimento las Raspberry y les proporciono conexión de red.\nPara poder alimentar las Raspberry por PoE he comprado un switch Netgear GS108PP con 8 puertos y con alimentación PoE en todos. Esto me permite tener hasta 7 Raspberry alimentadas y conectadas, ya que uno de los puertos lo utilizo para conectar el switch a la red.\nPara albergar todos los componentes he comprado un armario rack de 19\u0026rdquo; Phasak PHP 2106. El armario tiene 6U de espacio en total que será utilizado de la siguiente forma:\n 1U para una reglega de 8 tomas con interruptor 1U para el switch que va sobre una bandeja 2U para alojar hasta 12 Raspberry Pi 2U libres  Para colocar todas las Raspberry en fila en el armario rack, he imprimido este proyecto, disponible en Thingiverse. Ocupando 2U del rack se pueden tener 12 Raspberry. Cada Raspberry está en una bandeja extraíble, haciendo muy sencillo una sustitución. La mayoría de ejemplos que había visto para apilar Raspberry, lo hacian de tal forma que el recambio de una de ellas implicaría desmontar todo. Este es uno de los pocos que he encontrado que facilita el mantenimiento.\nAntes de poner el cluster en funcionamiento de forma continuada me gustaría tener un mecanismo para medir el consumo del mismo. Tengo pendiente comprar algún dispositivo que me permita medir el consumo y tener algún tipo de histórico para calcular su coste. He hecho una búsqueda rápida y he visto un montón de enchufes baratos que miden el consumo, aunque ninguno me ha convencido. Me gustaría tener una solución que se integre con Home Assistant, que es la solución que tengo en casa para la domótica. Este aspecto queda fuera del ámbito de este post y no me extenderé más en ello.\nConclusión La combinación de estos componentes me permite tener un cluster:\nCompacto El armario rack de 19\u0026rdquo; y 6U es un armario de reducidas dimensiones que puedo colocar en cualquier sitio de la casa.\nVentilado El armario rack dispone de 2 grandes ventiladores en la parte superior. Además cada Raspberry dispone de un ventilador ya que el HAT PoE incluye uno. Creo que es ventilación suficiente para dejar el cluster encendido de continuo sin miedo a que se sobrecaliente.\nOrdenado Los HAT PoE han ayudado mucho a que el armario no tenga demasiados cables en su interior y a que la regleta tenga más tomas disponibles para su uso.\nIluminado El armario rack dispone también de iluminación led, esto me da libertad para poder situar el armario rack en cualquier punto de la casa y poder hacer un mantenimiento del mismo sin problemas de falta de luz.\nExtensible Gracias al proyecto de thingiverse puedo colocar hasta 12 Rasperry ocupando 2U del armario. Con las 2U que me quedan libres podría:\n Colocar otras 12 raspberry pi Colocar algún dispositivo SAI Dedicarlo a almacenamiento etc  BOM  5x Raspberry Pi modelo 4b con 8GB de RAM 5x Samsung EVO Plus de 32GB 5x HAT PoE 1x Netgear GS108PP 1x Phasak PHP 2106 1x Reglega de 8 tomas con interruptor 1x Bandeja 1x Cables de red de 25cm 1x Tornillos y tuercas para armario rack 1x Tornillos M2.5 para Raspberry Pi 2x Varilla roscada M4 de 1m (comprado en ferretería) 8x Tuercas M4 (comprado en ferretería)  ","date":1600443060,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1601197920,"objectID":"ea7e4207f32ed47280f9cd6d665567af","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-i/","publishdate":"2020-09-18T15:31:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-i/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta primera parte explico cómo está configurado el cluster en cuanto a hardware se refiere.","tags":["cluster","raspberry"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte I)","type":"post"},{"authors":[],"categories":[],"content":"Sistema de automatización de fichajes  Objetivo El principal objetivo es simplificar el proceso de fichajes de una empresa\nUn objetivo secundario es el de utilizar tecnologías para seguir creciendo como profesional de la Informática.\n ## Contexto - Recordar cada una de las acciones a realizar - Para ciertas acciones hay que escribir un texto adicional - Login requerido para realizar cada una de las acciones - Intranet no adaptada al uso desde el móvil    ## Requisitos - Fichaje lo más fiel posible a la realidad - El usuario no tiene que recordar realizar ninguna acción - Las acciones manuales por parte del usuario serán muy sencillas - Se tendrán en cuenta los fichajes realizados directamente en la intranet    Solución La solución desarrollada es un chatbot de telegram:\nTimeHammerBot\nhttps://t.me/TimeHammerBot\nLo único necesario para poder utilizarla será disponer de un smartphone y tener instalada la aplicación de mensajería Telegram. También compatible con la versión web de Telegram\n ## Funcionamiento #### Trabajador 1. Registro en el chatbot - Hora de inicio y final de la jornada - Hora de inicio y final de la comida - Lugar de trabajo 1. Se olvida de volver a fichar    ## Funcionamiento #### Chatbot 1. Llegada la hora de una determinada acción - Comprueba el estado del trabajador - Si procede, notifica al trabajador 1. El trabajador recibe la notificación - Confirma/Postpone/Cancela la acción 2. El chatbot recibe la respuesta - Ejecuta la acción en la intranet - Se queda a la espera - Ignora la acción hasta el día siguiente    ## Ejemplo 1 Trabajador  lunes | comienzo jornada | 8:00 - A las 8:00 recibirá un mensaje preguntándole si ya ha comenzado a trabajar - Debajo del mensaje aparecerán una serie de botones: Sí, +5m, +10m, +15m, +20m, No - Con solo pulsar un botón el chatbot actuará en consecuencia    ## Ejemplo 2 Trabajador  vienes | comienzo jornada | 8:00 - Comienza a trabajar antes de lo normal - Fichaje manual en la intranet a las 7:30 - A las 8:00 el chatbot comprobará el estado y verá que no tiene nada que notificar    Extra I El chatbot busca molestar lo menos posible\n Fines de semana Festivos  Ciudad de trabajo   Vacaciones   Extra II No se persiste la contraseña de los usuarios, se guardan en memoria.\nSi se reinicia el contenedor que tiene en memoria las contraseñas, se enviará un mensaje a los trabajadores para que vuelvan a introducir su contraseña.\n DEMO  ## Objetivos cumplidos - Todos los fichajes requieren de una confirmación y son fieles a la realidad - El usuario ya no tiene que recordar realizar una determinada acción - La única acción manual del usuario consiste en pulsar un botón- El usuario ya no tiene que conectarse a una intranet - Al recuperar siempre el estado del usuario de la intranet, se posibilita combinar el uso de ambos sistemas para situaciones excepcionales    Stack tecnológico  Java Quarkus Docker Telegram Bots Kafka PostgreSQL   Event Driven Architecture I  Event Driven Architecture II  Roadmap I Reducción de llamadas a Comunytek En la versión actual se realizan:\n30 * 12 + 6 * 12 + 4 = 436 llamadas/usuario/día\nCon la versión mejorada se realizarían:\n3 llamadas/acción * 4 acciones/día/usuario = 12 llamadas/usuario/día\n Roadmap II Kubernetes I  Roadmap II Kubernetes II  Roadmap II Kubernetes III  Roadmap III  Anular el registro Modificar la configuración Mejorar validaciones en el registro Añadir tests Tunear configuración Kafka Añadir monitorización de módulos NLP Modulo de administración   ## Chatbots I - Los chatbots son una herramienta mucho potencial que permite aplicar un nuevo enfoque para resolver ciertos problemas - Los usuarios están cada vez más acostumbrados a las aplicaciones de mensajería - Tienen peor fama de la que se merecen porque muchos de los que se hacen llamar chatbots, hacen un mal (o nulo) procesamiento del lenguaje natural y realmente se trata de una sucesión de condiciones lógicas que ejecutan ciertas acciones    ## Chatbots II - Con este proyecto se muestra un **enfoque diferente** de chatbot, basado en el uso de **comandos**. Que mediante el uso de diferentes **teclados** que se **adaptan** al tipo de respuesta que esperas del usuario, **mejora** mucho la **usabilidad**    Caso de Uso Nuevo canal de comunicación para la realización de guardias\n","date":1597384200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599290520,"objectID":"0fce65b41a51745a77269db256dfe812","permalink":"https://diegocastroviadero.com/slides/timehammer/","publishdate":"2020-08-14T05:50:00Z","relpermalink":"/slides/timehammer/","section":"slides","summary":"Sistema de automatización de fichajes","tags":[],"title":"TimeHammer","type":"slides"},{"authors":null,"categories":null,"content":"Este es un proyecto personal en el que llevo trabajando desde comienzos del 2020, poco antes del confinamiento por la COVID-19. Consiste en un sistema que permite recordar y simplificar la realización de los fichajes en una empresa.\nSe trata de TimeHammerBot un chatbot de Telegram en el cual el trabajador se registra indicando su lugar y horario habitual de trabajo. Una vez registrado, el chatbot se encargará de recordarle los momentos en los que se debe realizar un fichaje. No sólo se trata de recordatorios en los diferentes momentos de fichaje, sino que el chatbot propone una serie de botones integrados en los mensajes de recordatorio, que al ser pulsados ejecutan la acción de fichar.\nSe ha desarrollado una arquitectura orientada a eventos EDA. El proyecto se ha dividido en diversos módulos, cada uno con una responsabilidad, que se comunican entre si mediante el envío de mensajes. Estos mensajes representan los diferentes eventos que desencadenan la lógica de negocio.\nPara el desarrollo se ha utilizado Quarkus, que es un stack basado en java que posibilita la compilación a código nativo. Quarkus permite tanto la programación imperativa como la reactiva. En este proyecto se ha optado por la programación reactiva.\nPara el envío de los mensajes se ha utilizado Kafka puesto que la integración con Quarkus es muy sencilla.\nPara la ejecución en producción se utiliza Docker. Cada uno de los módulos que componen el proyecto tiene una imagen de Docker asociada. En el entorno de producción se ejecutan contenedores de dichas imágenes. Actualmente son se utiliza ningún orquestador de contenedores, directamente se están arrancando con docker-compose. El siguiente paso planificado es la utilización de kubernetes como orquestador de contenedores.\n","date":1597294800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599290280,"objectID":"915e32669415332108040900e6a5c2dc","permalink":"https://diegocastroviadero.com/project/timehammer/","publishdate":"2020-08-13T05:00:00Z","relpermalink":"/project/timehammer/","section":"project","summary":"Sistema de automatización de fichajes","tags":["Java","Quarkus","EDA","Kafka","Docker"],"title":"TimeHammer","type":"project"},{"authors":null,"categories":null,"content":"Contexto En el año 2019 hubo un cambio de ley que obliga a todas las empresas de España a proporcionar información sobre la jornada laboral de sus trabajadores, lo que comunmente conocemos como fichajes.\nMi empresa se ha adaptado al cambio de legislación añadiendo una nueva sección en la intranet para que cada empleado pueda registrar la jornada laboral. El enfoque que ha seguido mi empresa es el fichaje \u0026ldquo;en tiempo real\u0026rdquo;, es decir, se toma el momento en el que se están registrando las acciones como el momento en el que las realizas. Esto obliga a fichar en el momento real en el que empiezas a trabajar, en el que comienzas a comer, en el que terminas de comer\u0026hellip; No existe ninguna posibilidad de corrección por parte de los trabajadores, si se olvida registrar alguna de las acciones hay que escribir un email al responsable para indicarlo.\nEste enfoque de \u0026ldquo;tiempo real\u0026rdquo; no es el único posible, he visto otras empresas que también proporcionan un apartado en su intranet, pero que permiten hacer el fichaje \u0026ldquo;en diferido\u0026rdquo;.\nCuestiones a parte serían si estas implementaciones cumplen con la ley o qué responsabilidades tiene el trabajador o qué pasaría si se hace una inspección y los fichajes del trabajador no son correctos.\nProblema La solución tomada por mi empresa no es una solución pensada para el trabajador que sea cómoda de usar, todo lo contrario:\n El trabajador tiene que recordar todas las acciones que tiene que realizar Para ciertas acciones el trabajador tiene no sólo que realizar la acción, sino que tiene que escribir un texto válido para dicha acción Para realizar cada una de las acciones el trabajador tiene que acceder a la intranet, teniendo que introducir sus credenciales Algunas de las acciones se realizan desde sitios donde no hay un ordenador, por lo que hay que acceder a la intranet desde el móvil cuando la intranet no está adaptada para ello. Los menús son muy pequeños y es difícil llegar a la zona de fichajes  Objetivo Me he propuesto simplificar todo este proceso de tal forma que los fichajes se realicen de una manera sencilla, y lo más fieles posible a la realidad. Además utilizaré tecnologías que me permitan seguir desarrollándome como profesional de la Informática.\nRequisitos Estos son los requisitos funcionales que guiarán el planteamiento y desarrollo de la solución:\n Fichaje lo más fiel posible a la realidad Las acciones manuales por parte del usuario serán muy sencillas Se tendrán en cuenta los fichajes realizados directamente en la intranet  Solución La solución desarrollada es un chatbot de telegram: TimeHammerBot. Lo único necesario para podeer utilizarla será disponer de un smartphone y tener instalada la aplicación de mensajería Telegram.\nFuncionamiento El trabajador se registrará en el chatbot TimeHammerBot de Telegram. Para ello tendrá que indicar la empresa en la que trabaja, los credenciales para acceder a la intranet donde se realiza el fichaje manual y los horarios habituales: hora de comienzo y fin de la jornada laboral y hora de comienzo y fin de la comida (para cada día de la semana). Una vez realizado el registro podrá olvidarse de volver a acceder a la intranet para realizar un fichaje. A partir de ese momento será el chatbot quien le recuerde a las horas configuradas, la realización de las acciones pertinentes. Además junto con cada recordatorio, se proporcionarán una serie de botones que permitirán confirmar la realización de dichas acciones.\nPor ejemplo, si el trabajador ha indicado que los lunes suele comenzar la jornada laboral a las 8:00, a esa hora recibirá un mensaje en Telegram preguntándole si ya ha comenzado a trabajar. Debajo del mensaje aparecerán una serie de botones: \u0026ldquo;Sí\u0026rdquo;, \u0026ldquo;+5m\u0026rdquo;, \u0026ldquo;+10m\u0026rdquo;, \u0026ldquo;+15m\u0026rdquo;, \u0026ldquo;+20m\u0026rdquo;, \u0026ldquo;No\u0026rdquo;. Al pulsar el botón \u0026ldquo;Sí\u0026rdquo;, el chatbot se encargará de registrar el inicio de la jornada en la intranet. Al pulsar los botones \u0026ldquo;+Xm\u0026rdquo;, se le pedirá al chatbot que se espere X minutos antes de volver a preguntar. Al pulsar el botón \u0026ldquo;No\u0026rdquo;, se le indicará al chatbot que ese día no se trabaja y hasta el día siguiente no volverá a preguntar nada.\nEl chatbot recuperará de la intranet las vacaciones del trabajador con el objetivo de no molestar durante ese periodo de tiempo. También tendrá en cuenta los días festivos de la ciudad de trabajo del trabajador (motivo por el cual durante el registro hay que indicar la ciudad de trabajo).\nEl chatbot es un mero intermediario, no guardará en ningún momento los fichajes del trabajador. Para conocer el estado de un trabajador lo recuperará de la intranet de la empresa del trabajador. De esta forma se puede combinar el uso del chatbot junto con la realización de ciertas acciones de forma manual. Por ejemplo, si el trabajador ha indicado que los viernes suele comenzar a trabajar a las 8:00, pero excepcionalmente, un viernes comienza su jornada a las 7:30, podrá acceder a la intranet y registrar su fichaje a las 7:30. Cuando sean las 8:00 el chatbot tendrá en cuenta las posibles acciones realizadas manualmente en la intranet antes de preguntar nada. Por lo que en este caso, a las 8:00 el chatbot no preguntará nada al trabajador.\nCon este modelo de funcionamiento se cumplen los 3 requisitos planteados para el proyecto:\n Todos los fichajes requerirán de una confirmación por parte del usuario y serán fieles a la realidad. El usuario se olvida de tener que conectarse a una intranet y registrar una serie de acciones y en su lugar lo único que tiene que hacer es pulsar un botón cuando le llega un mensaje al Telegram. Al no guardar el estado de los trabajadores y recuperarlo siempre de la intranet, se posibilita combinar el uso de ambos sistemas.  Detalles Para conocer más detalles sobre el proyecto puedes acceder aquí\nConclusión Este proyecto ha supuesto un reto bastante interesante por diversos motivos:\n- Llevar un proyecto adelante de principio a fin\n El camino que hay que seguir desde que se tiene una idea hasta que esta se materializa siempre es complicado. A lo largo de este camino existen diversos momentos, en los que lo más fácil es no complicarse y ceder en el intento. Llegar a desplegar en producción una primera versión estable y funcional es motivo suficiente para sentirse orgulloso.\n - Afrontar un nuevo paradigma de programación\n Cambiar la manera de pensar no es trivial. Tareas que considerabas sencillas, de repente, se convierten en complicados rompecabezas. Ante la más mínima complicación es tentador volver a las antiguas costumbres para salir del paso y seguir avanzando. Ha resultado agotador ser fiel a programación reactiva.\n - Nuevas tecnologías\n En este proyecto he utilizado muchas tecnologías desconocidas para mi: Quarkus, Kafka, EDA, compilación nativa de java, imágenes distroless. Para mi siempre es motivador enfrentarme a un nuevo framework, lenguaje, herramienta\u0026hellip; me recuerda a cuando era niño y me regalaban un juguete. Lo que resulta un verdadero reto es realizar un proyecto en el que la gran mayorías de las tecnologías son desconocidas y pasas más tiempo en las páginas de documentación que programando.\n - Ponerse un objetivo y ceñirse a él\n Cuando no tienes a un jefe que te va guiando hacia una meta es complicado no desviarse del camino y resulta muy sencillo irse por las ramas. Más aún cuando tienes un montón de \u0026ldquo;juguetitos\u0026rdquo; nuevos que probar e investigar. Este proyecto no ha sido una excepción, de hecho, la solución final es la tercera que se ha desarrollado desde cero. El proyecto comenzó siendo serverless, basándose en el uso de Firebase. Después se descartó la idea de serverless y pasó a ser un monolito desarrollado en Quarkus. Finalmente se ha mantenido el uso de Quarkus, pero se ha modularizado implementando una arquitectura orientada a eventos.\n Se trata de una primera versión funcional con mucho margen de mejora. He incorporado una gran cantidad de novedades tecnológicas, dada mi experiencia,y hasta el momento no he podido profundizar mucho en ellas para poder tener esta primera versión funcional lo antes posible.\n","date":1580494860,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599288360,"objectID":"f0341a7a0828ccbec3bc1dd1ee582041","permalink":"https://diegocastroviadero.com/post/como-automatizar-los-fichajes-de-mi-empresa/","publishdate":"2020-01-31T18:21:00Z","relpermalink":"/post/como-automatizar-los-fichajes-de-mi-empresa/","section":"post","summary":"En este post explicaré el proyecto que he desarrollado para automatizar los fichajes de mi empresa","tags":["timehammer","chatbot","telegram"],"title":"Cómo he automatizado los fichajes de mi empresa","type":"post"},{"authors":null,"categories":null,"content":"Llevo ya unos meses pensando en renovar los equipos que tengo, bien porque se han quedado desfasados o bien porque quiero ampliar sus funcionalidades y se quedan cortos de recursos. Actualmente dispongo de los siguientes equipos:\n portátil de 13\u0026rsquo; con windows (ligero) portátil de 15\u0026rsquo; con windows (antiguo) portátil de 17\u0026rsquo; con windows (el más potente) raspberry pi con raspbian para la domótica raspberry pi con raspbian para la gestión de finanzas iMac NAS con 2 discos de 2TB en RAID0  El NAS cumple con múltiples funciones:\n almacenamiento de documentos almacenamiento de backups centro multimedia centro de descargas  Para el almacenamiento de documentos utilizo software propio de QNAP que me permite tener sincronizados determinados directorios de un equipo con el NAS. Además tengo la posibilidad de acceder a los mismos, también a través de aplicaciones de QNAP, desde los dispositivos móviles.\nPara la realización de los backups utilizo software propio de QNAP para los equipos Windows, que me permite programar backups de forma periódica. En el caso del iMac, utilizo TimeMachine que lo hace de forma automática y transparente.\nQuien realmente cumple con la función de centro multimedia es Plex Media Server, que está instalado en el NAS, y es quien me permite visualizar el contenido multimedia a través de la Smart TV y de los dispositivos móviles.\nPara la realización de descargas utilizo un cliente BitTorrent instalado en el NAS, que me permite controlarlo desde los dispositivos móviles.\nLo que me gustaría es retirar algunos de los portátiles que tengo junto con el iMac y en su lugar comprarme un buen PC que sea potente y que me permita realizar proyectos personales de Data Science.\nMotivación Una renovación del hardware no tendría por qué llevarme a un replanteamiento de la organización en lo que respecta al almacenamiento. Sin embargo, existen una serie de inconvenientes/mejoras pendientes que llevo arrastrando desde hace un tiempo y que son los verdaderos motivadores del cambio:\n En el iMac tengo configurado el TimeMachine para hacer los backups contra el NAS. Parece que no funciona muy bien, porque desde que lo configuré sale un aviso en el NAS indicando que hay datos erróneos en alguno de los volúmenes. Además, el iMac apenas lo utilizo y es uno de los equipos que quiero jubilar Sólamente uno de los portátiles con Windows tiene configurados los backups y la sincronización de documentos Las Raspberry PI no tienen configurado ningún tipo de backup contra el NAS y, tras haber investigado, QNAP no ofrece demasiadas opciones para Linux Me gustaría tener una única solución tanto de backups como de sincronización de documentos, para todos los sistemas operativos El QNAP funciona muy lento, las opciones de ampliación de sus recursos hardware son muy limitadas y además quiero ampliar sus funcionalidades (ej: añadirle un repositorio de código, poder hacer seguimiento de series y películas con couchpotato o alternativas similares, etc.)  Así que aprovechando que voy a hacer cambios en el hardware y teniendo en cuenta todos los puntos anteriores he decidido hacer un cambio radical.\nQué me gustaría tener Me gustaría tener lo siguiente:\n Tener backups de las Raspberry PI de forma periódica y automática Tener sincronizados con el NAS algunos directorios tanto de equipos Windows como Linux Tener las fotos/videos realizadas con dispositivos móviles guardadas directamente en el NAS de forma automática Tener forma de visualizar a través del móvil las fotografías del NAS Tener forma de visualizar a través del móvil los documentos del NAS Poder montar un volumen del NAS en cualquiera de los portátiles o PC para hacer un backup manual inicial de documentos o fotos Que el NAS haga de forma periódica un backup encriptado a algún cloud Disponer de un cliente de descargas de BitTorrent y poder controlarlo a través del móvil Utilizar Plex Media Server como media center Añadir Radarr, Sonarr y Jackett (o CouchPotato) para el seguimiento de series y películas y descargas automatizadas Tener un repositorio de código git Poder editar documentos, hojas de cálculo, presentaciones, diagramas directamente a través del NAS Aplicación de mensajería privada Aplicación de notas privada Aplicación de calendario privada Poder ampliar libremente los recursos del NAS en un futuro Poder ampliar libremente la funcionalidad del NAS  Alternativas La primera disyuntiva a la que me enfrento es si comprar otro NAS ya montado (al estilo del QNAP) o montármelo yo mismo. La ventaja de comprar uno ya montado es que es \u0026ldquo;enchufar y listo\u0026rdquo;, con el inconveniente de que este tipo de NAS no son demasiado flexibles. La venjata de montarse un NAS es que son totalmente customizables y extensibles, la pega es que requieren de mucho tiempo de investigación, selección de componentes, montaje, configuración y selección de software.\nNAS ya montado He descubierto que Synology tiene mejor integración con linux. He encontrado dos modelos que se ajustan a los requisitos: DS918+ y DS1618+.\nDS918+ Cumple con casi todos los requisitos, la única excepción es la ampliación de recursos. Tiene 4 bahías y la posibilidad de comprar una extensión que permitiría añadir más discos. De serie viene con 4GB de RAM ampliables a 8GB, aunque en algún foro he leído que se le pueden meter 16GB (aunque esto está por comprobar). El procesador tiene 4 cores a 2.1GHz. Tiene una app store de aplicaciones que permite ampliar las funcionalidades del NAS y en caso de no encontrar alguna se podría usar Docker.\nContras:\n el precio 550-600€ el procesador no se puede cambiar, y la RAM sólo se puede ampliar con garantías hasta 8GB las aplicaciones para el móvil no tienen muy buenas valoraciones lo veo justo tanto de procesador como de memoria RAM para las funcionalidades que quiero que ofrezca  DS1618+ Cumple con casi todos los requisitos, la única excepción es la ampliación de recursos. Tiene 6 bahías y la posibilidad de comprar una extensión que permitiría añadir más discos. De serie viene con 4GB de RAM ampliables a 32GB. El procesador tiene 4 cores a 2.1GHz. Tiene una app store de aplicaciones que permite ampliar las funcionalidades del NAS y en caso de no encontrar alguna se podría usar Docker.\nContras:\n el precio 750€ el procesador no se puede cambiar las aplicaciones para el móvil no tienen muy buenas valoraciones lo veo justo de procesador para las funcionalidades que quiero que ofrezca  NAS DIY He estado investigado diferentes alternativas de SO orientados a montar un NAS, y he encontrado que el más usado es FreeNas. También he encontrado otra alternativa que me gusta más: unRaid.\nMuchas de las funcionalidades que quiero cubrir no son ofrecidas directamente por esos SOs, sino que hay que instalar algunos plugins/aplicaciones/contenedores para cubrirlas.\nFreeNas Está basado en FreeBSD y soporta el sistema de ficheros ZFS, que por lo que he leído debe de ser muy bueno y solventa los inconvenientes de RAID.\nContras:\n al estar basado en FreeBSD no tiene soporte nativo de Docker muchas de las funcionalidades se cubren con aplicaciones/plugins que hay que buscar, instalar y configurar, con el esfuerzo que esto conlleva la existencia de aplicaciones móviles para cubrir ciertos requisitos depende de las aplicaciones/plugins que se instalen  unRaid Es un SO basado en Debian, por lo que tiene soporte nativo de Docker. Como se puede deducir de su nombre, no soporta RAID. Lo que hace, es montar un array con todos los discos, dando la visión de que se trata de un único disco. Como mecanismo de protección tiene un sistema de paridad que permitiría el fallo de hasta 2 discos del sistema sin perder los datos. Los datos en los discos se almacenan como en un disco normal, de tal forma que si extraemos un disco del array y lo conectamos a otro dispositivo, podremos ver su contenido.\nContras:\n no es gratuito (pago único de 59-129€, dependiendo del número de discos que se quieran usar) muchas de las funcionalidades se cubren con aplicaciones/plugins que hay que buscar, instalar y configurar, con el esfuerzo que esto conlleva la existencia de aplicaciones móviles para cubrir ciertos requisitos depende de las aplicaciones/plugins que se instalen  Comparativa    Requisito Synology FreeNas unRaid     Tener backups de las Raspberry PI de forma periódica y automática 👍 👍 1 👍 1   Tener sincronizados con el NAS algunos directorios tanto de equipos Windows como Linux 👍 👍 2 👍 2   Tener las fotos/videos realizadas con dispositivos móviles guardadas directamente en el NAS de forma automática 👍 👍 2 👍 2   Tener forma de visualizar a través del móvil las fotografías del NAS 👍 👍 2 3 👍 2 3   Tener forma de visualizar a través del móvil los documentos del NAS 👍 👍 2 👍 2   Poder montar un volumen del NAS en cualquiera de los portátiles o PC para hacer un backup manual inicial de documentos o fotos 👍 👍 👍   Que el NAS haga de forma periódica un backup encriptado a algún cloud 👍 👍 1 👍 1   Disponer de un cliente de descargas de BitTorrent y poder controlarlo a través del móvil 👍 👍 4 👍 5   Utilizar Plex Media Server como media center 👍 👍 4 👍 5   Añadir Radarr, Sonarr y Jackett (o CouchPotato) para el seguimiento de series y películas y descargas automatizadas 👍 ❓ 👍 5   Tener un repositorio de código git 👍 ❓ 👍 5   Poder editar documentos, hojas de cálculo, presentaciones, diagramas directamente a través del NAS 👍 👍 2 👍 2   Aplicación de mensajería privada 👍 👍 2 👍 2   Aplicación de notas privada 👍 👍 2 👍 2   Aplicación de calendario privada 👍 👍 2 👍 2   Poder ampliar libremente los recursos del NAS en un futuro 👎 👍 👍   Poder ampliar libremente la funcionalidad del NAS 👍 👍 6 👍 5    Conclusión Me da miedo de que me pase lo mismo que lo que me ha pasado con el QNAP: que me quede corto de recursos con el paso del tiempo y tener poco margen de maniobra. Se trata de dispositios con un coste elevado, como para tener que verse obligado a cambiarlo por el mero hecho de necesitar más RAM (con la inversión de tiempo que hay que realizar para hacer el cambio).\nDecididamente voy a optar por un NAS DIY, y concretamente por uno con unRaid. He visto unos cuantos análisis y videos de su funcionamiento y me ha gustado bastante. Creo que me convence más la idea de array de discos que la de montar un RAID.\nAdemás que creo que con un mismo equipo puedo cubrir las 2 necesidades: disponer de un PC potente y tener un NAS con más funcionalidades que el actual. En primer lugar compraré el PC que quería comprarme y le instalaré unRaid. Sin me gusta como funciona, le haré una ampliación de hardware. Si por lo que fuera no quedo contento con el resultado, el equipo me vale como PC y volveré a valorar qué hacer para el NAS.\nCuando haya elegido el hardware, montado el equipo, instalado y configurado unRaid, escribié otro post con la situación final.\n  Usando Duplicati \u0026#x21a9;\u0026#xfe0e;\n Usando Nexcloud \u0026#x21a9;\u0026#xfe0e;\n Plex Media Server también permite ver fotos, quiero ver si la gestión de álbumes es similar a google fotos o al menos mejor que la de Nexcloud \u0026#x21a9;\u0026#xfe0e;\n Seguro que se puede pero hay que buscar una aplicación que permita hacerlo \u0026#x21a9;\u0026#xfe0e;\n Con algún contenedor Docker \u0026#x21a9;\u0026#xfe0e;\n Usando los Jail de FreeBSD (no tan extendido como los contenedores Docker) \u0026#x21a9;\u0026#xfe0e;\n   ","date":1580411760,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1580546460,"objectID":"85208c75b05a0a80995309e553ccb18a","permalink":"https://diegocastroviadero.com/post/como-quiero-organizar-mi-almacenamiento/","publishdate":"2020-01-30T19:16:00Z","relpermalink":"/post/como-quiero-organizar-mi-almacenamiento/","section":"post","summary":"Llevo ya un tiempo queriendo hacer una renovación de los equipos que tengo y ya de paso reorganizar mi solución para el almacenamiento. En este post plasmaré cómo me gustaría reorganizarlo todo.","tags":["unRaid"],"title":"Cómo quiero organizar mi almacenamiento","type":"post"},{"authors":null,"categories":null,"content":"Prerequisitos  Tener un dominio en Google Domains Tener un repositorio en GitHub (ej: https://github.com/dicastro/dicastro.github.io)   Este repositorio no tiene por qué ser público, en mi caso se trata de un repositorio privado.\n Pasos 1 - Activa GitHub Pages Para ello en la configuración del repositorio de GitHub:\n Activa GitHub Pages seleccionando una rama desde la cuál se va a servir el contenido Configura un Custom Domain (ej: diegocastroviadero.com)  2 - Apunta el dominio (diegocastroviadero.com) a GitHub Pages Para ello en Google Domains:\n Añade un Custom resource record de tipo A apuntando a GitHub Pages     Nombre Tipo TTL Datos     @ A 1h 185.199.108.153         185.199.109.153         185.199.110.153         185.199.111.153     En este caso @ hace referencia al propio dominio (diegocastroviadero.com)\n  Si las IPs anteriores se han quedado desfasadas, podrás encontrar los valores actualizados aquí\n 3 - Apunta el subdominio www a GitHub Pages Para ello en Google Domains:\n Añade un Custom resource record de tipo CNAME apuntando a la url de GitHub Pages correspondiente al repositorio en cuestión (ej: dicastro.github.io)     Nombre Tipo TTL Datos     @ CNAME 1h dicastro.github.io    4 - Configura HTTPS Para ello en la configuración del repositorio de GitHub:\n Fuerza el uso de HTTPS  Y en Google Domains:\n Añade un Custom resource record de tipo CAA permitiendo la emisión de certificados para el dominio (ej: diegocastroviadero.com) a la entidad emisora de certificados, que en el caso de GitHub es letsencrypt     Nombre Tipo TTL Datos     @ CAA 1h 0 issue \u0026ldquo;letsencrypt.org\u0026rdquo;     En este caso @ hace referencia al propio dominio (diegocastroviadero.com)\n  Para obtener el valor de la columna Datos de la entrada de tipo CAA se puede hacer uso de esta utilidad\n Referencias  https://www.techrepublic.com/article/how-to-add-a-certificate-authority-authorization-record-in-google-domains https://dev.to/trentyang/how-to-setup-google-domain-for-github-pages-1p58  ","date":1580236440,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1580323080,"objectID":"659a0889ce409b1da96f29f1d2c8f4c4","permalink":"https://diegocastroviadero.com/post/como-configurar-un-dominio-propio-de-google-domains-en-github-pages-y-con-https-activado/","publishdate":"2020-01-28T18:34:00Z","relpermalink":"/post/como-configurar-un-dominio-propio-de-google-domains-en-github-pages-y-con-https-activado/","section":"post","summary":"En este post se va a explicar cómo configurar un dominio propio, comprado en Google Domains, en GitHub Pages y cómo activar HTTPS","tags":["Google Domains","GitHub Pages","Let's encrypt"],"title":"Cómo configurar un dominio propio de Google Domains en GitHub Pages y con HTTPS activado","type":"post"},{"authors":null,"categories":null,"content":"Este es mi primer post de prueba.\nLa idea es utilizar este blog para escribir artículos relacionados con algunos de mis intereses a modo de base de datos para posteriores consultas. Serán artículos sobre algún tema nuevo que esté investigando o artículos sobre cómo resolver problemas a los que me haya enfrentado.\n","date":1576337940,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1576337940,"objectID":"664bde57003ea7f7bec74d75c0246ab3","permalink":"https://diegocastroviadero.com/post/hola-mundo/","publishdate":"2019-12-14T15:39:00Z","relpermalink":"/post/hola-mundo/","section":"post","summary":"Este es mi primer post","tags":null,"title":"Hola Mundo!","type":"post"},{"authors":null,"categories":null,"content":"Este proyecto ha sido realizado como trabajo final del máster en Data Science \u0026amp; Big Data de la U-TAD.\nPara el desarrollo del proyecto se han realizado las siguientes tareas:\n Estudio del estado del arte en lo que a la detección de objetos se refiere Desarrollo de una implementación de YOLO V3 y de YOLO V3 Lite en python Búsqueda y preparación de un conjunto de imágenes Entrenamiento de varios modelos YOLO con distintas configuraciones y realización de estudio comparativo de los resultados obtenidos Transformación del modelo entrenado para ser explotado en un dispositivo móvil Desarrollo de aplicación android para la explotación del modelo  El proyecto se compone de los siguientes repositorios:\n   Repositorio Descripción     \rtfm Contiene una implementación en python de YOLO V3 y YOLO V3 Lite   \rtfm-android Contiene una aplicación móvil android para la explotación del modelo entrenado mediante el uso de Tensor Flow Lite   \rtfm-doc Contiene la memoria del TFM    Referencias:\n Las imágenes utilizadas para entrenar los modelos han sido obtenidas de kaggle La aplicación móvil se basa en un ejemplo de tensorflow lite La implementación de YOLO V3 es un fork de este repositorio y la implementación de YOLO V3 Lite está basada en este repositorio. Se han unificado ambas implementaciones en una única, se han añadido más opciones de configuración de los modelos y se soportan más formatos de etiquetas de las imágenes  ","date":1569715200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1569715200,"objectID":"d882fc2296783c8bc0aa60fe7de34f77","permalink":"https://diegocastroviadero.com/project/sistema-de-deteccion-automatica-de-baches-en-el-asfalto-a-partir-de-imagenes/","publishdate":"2019-09-29T00:00:00Z","relpermalink":"/project/sistema-de-deteccion-automatica-de-baches-en-el-asfalto-a-partir-de-imagenes/","section":"project","summary":"TFM del máster en Data Science \u0026 Big Data de la U-TAD","tags":["Data Science","Deep Learning","YOLO"],"title":"Sistema de detección automática de baches en el asfalto a partir de imágenes","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"https://diegocastroviadero.com/cv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/cv/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"6880d30a4afb347490251c2f38986b57","permalink":"https://diegocastroviadero.com/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/posts/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://diegocastroviadero.com/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]