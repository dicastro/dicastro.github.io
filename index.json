[{"authors":["admin"],"categories":null,"content":"Soy un ingeniero de software con más de 10 años de experiencia en el sector. En todos estos años he pasado por diversas empresas ejerciendo distintos roles y he podido desarrollarme profesionalmente en distintas áreas.\nEste bagaje incluye el paso por grandes consultoras multinacionales, en las que he participado en diversos proyectos de distinta índole, he podido trabajar en proyectos en el extranjero integrándome en diferentes culturas, coordinar pequeños equipos de desarrollo, acompañar en los inicios a perfiles junior, formar parte de proyectos con multitud de equipos y numerosos, etc.\nTambién he tenido la ocasión de trabajar en una startup prácticamente desde el momento de su creación, lo cual me permitió experimentar lo difícil que es crear algo desde cero. Una experiencia muy valiosa que me permitió ver de cerca el otro lado de la moneda, el del empresario.\nMe apasiona la programación y tengo muchas inquietudes que me hacen estar en un aprendizaje continuo. Esto es lo que me ha llevado a estudiar un máster en Data Science \u0026amp; Big Data. Un área apasionante, con mucho que decir en los próximos años y del cual me gustaría formar parte en un futuro cercano.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"es","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://diegocastroviadero.com/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"Soy un ingeniero de software con más de 10 años de experiencia en el sector. En todos estos años he pasado por diversas empresas ejerciendo distintos roles y he podido desarrollarme profesionalmente en distintas áreas.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"En otro post ya expliqué cómo medía el consumo de un cluster de Raspberry Pi mediante el uso de un Sonoff Pow R2. Es importante calibrar este dispositivo antes de utilizarlo para que sus mediciones sean lo más precisas posibles.\nEn este post voy a explicar cómo calibrarlo. Para ello será necesario disponer de un medidor de corriente. Yo he utilizado un ZHURUI PR10-C EU16A que no es muy caro y funciona bastante bien. Este dispositivo permite visualizar al mismo tiempo el voltaje, la corriente y la potencia consumidas. Esto último puede parecer una nimiedad, pero más adelante se mostrará cómo este detalle facilita mucho el proceso de calibración.\nPara realizar la calibración se conecta el Zhurui a una toma de corriente y el Sonoff al primero. Este proceso consiste en ir conectado al Sonoff diversos dispositivos con diferentes consumos e ir anotando tanto las mediciones del Zhurui como las del Sonoff.\nEn mi caso he utilizado los siguientes dispositivos:\n Un flexo con un halógeno (11W) Un flexo con una bombilla incandescente (60W) Una aspiradora (máximo 800W) Una plancha (2000W)  He ido conectando uno a uno cada uno de los dispositivos anteriores al Sonoff, que a su vez está conectado al medidor de consumo, y he ido anotando las mediciones de ambos. Para tomar las medidas del Sonoff, he utilizado un portátil desde el cual he accedido a la consola del ESPHome. Este portátil lo he colocado junto a la toma de corriente donde se encuentra el Zhurui, de tal forma que mediante una fotografía puedo capturar las lecturas de ambos dispositivos.\nEn este paso es donde se agradece que el medidor de corriente muestre en pantalla al mismo tiempo todos los valores interesantes, ya que con una única instantánea se obtiene toda la información necesaria. Aquí se puede ver un ejemplo de las lecturas obtenidas al conectar la bombilla incandescente:\nUna vez se ha realizado una captura para cada uno de los dispositivos se dispone de toda la información necesaria para calibrar el Sonoff. Por cómo está diseñado ESPHome este paso es muy sencillo. Simplemente hay que configurar unos filtros en los que se anota la medida del medidor de corriente junto con la del sonoff.\nDonde antes había algo como lo siguiente:\n# Current sensor current: name: \u0026quot;RPI Cluster Current\u0026quot; icon: mdi:current-ac unit_of_measurement: A accuracy_decimals: 3  Ahora habrá algo parecido a esto:\n# Current sensor current: name: \u0026quot;RPI Cluster Current\u0026quot; icon: mdi:current-ac unit_of_measurement: A accuracy_decimals: 3 filters: # Map from sensor -\u0026gt; measured value - calibrate_linear: - 0.0 -\u0026gt; 0.010 - 0.15855 -\u0026gt; 0.153 - 0.25773 -\u0026gt; 0.265 - 2.45250 -\u0026gt; 2.519 - 3.02082 -\u0026gt; 3.066 - 3.41044 -\u0026gt; 3.464 - 8.73604 -\u0026gt; 8.837 # Make everything below 0.01A appear as just 0A. # Furthermore it corrects 0.01A for the power usage of the sonoff plus the led of the multi-socket. - lambda: if (x \u0026lt; (0.01 - 0.01)) return 0; else return (x - 0.01);   En este post se puede ver el código completo del Sonoff\n Y algo parecido para el sensor de potencia:\n# Power sensor power: name: \u0026quot;RPI Cluster Power\u0026quot; icon: mdi:gauge unit_of_measurement: W accuracy_decimals: 0 id: rpiclusterpower filters: # Map from sensor -\u0026gt; measured value - calibrate_linear: - 0.0 -\u0026gt; 1.19 - 15.33994 -\u0026gt; 16.98 - 57.21655 -\u0026gt; 59.42 - 261.44540 -\u0026gt; 272.0 - 459.74557 -\u0026gt; 471.6 - 741.94073 -\u0026gt; 761.0 - 1905.09253 -\u0026gt; 1957.0 # Make everything below 2W appear as just 0W. # Furthermore it corrects 1.19W for the power usage of the sonoff plus the led of the multi-socket. - lambda: if (x \u0026lt; (2 + 1.19)) return 0; else return (x - 1.19);  Y para el de voltaje:\n# Voltage sensor voltage: name: \u0026quot;RPI Cluster Voltage\u0026quot; icon: mdi:flash unit_of_measurement: V accuracy_decimals: 1 filters: # Map from sensor -\u0026gt; measured value - calibrate_linear: - 0.0 -\u0026gt; 0.0 - 226.84409 -\u0026gt; 225.6 - 225.37788 -\u0026gt; 224.9 - 225.54657 -\u0026gt; 224.6 - 224.83321 -\u0026gt; 224.5 - 224.59578 -\u0026gt; 224.0 - 224.23352 -\u0026gt; 223.9  ESPHome realiza una regresión lineal en base a los valores anteriores (utilizando una función de ajuste de mínimos cuadrados) para \u0026ldquo;corregir\u0026rdquo; las mediciones realizadas por el Sonoff.\n No lo he mencionado hasta ahora, pero también hay que realizar una captura de las medidas sin ningún dispositivo conectado al Sonoff.\n Conclusión Como se puede ver la calibración de un dispositivo Sonoff es muy sencilla. Cuanto más preciso sea el medidor de corriente externo utilizado, mejor será la calibración del Sonoff. Es importante utilizar dispositivos con consumos diversos que cubran todo el espectro para que la calibración se ajuste lo máximo a la realidad. En el caso de adquirir varios Sonoff, cada uno debería ser calibrado de forma independiente.\n","date":1603692240,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1603906740,"objectID":"d3a57698b76acae6bb1519debbe1412e","permalink":"https://diegocastroviadero.com/post/como-calibrar-un-sonoff-pow-r2/","publishdate":"2020-10-26T06:04:00Z","relpermalink":"/post/como-calibrar-un-sonoff-pow-r2/","section":"post","summary":"En este post explico cómo calibrar un Sonoff Pow R2 para que sea más preciso en sus mediciones.","tags":["sonoff","esphome"],"title":"Cómo calibrar un Sonoff Pow R2","type":"post"},{"authors":null,"categories":null,"content":"En este post explicaré cómo expongo mi instalación local de Home Assistant a Internet a través de un dominio propio y de forma segura.\nLa instalación local de Home Assistant no es más que una raspberry pi conectada al router de mi proveedor de internet.\nEl dominio propio es un dominio adquirido en google domains, concretamente se trata del dominio popishome.com.\nEl acceso al Home Assistant es seguro porque se va a realizar utilizando el protocolo HTTPs. Se cifrará la conexión con un certificado de Let\u0026rsquo;s Encrypt.\nCon estos mimbres se plantean varias cuestiones:\n La raspberry pi está conectada al router del proveedor a internet por lo que la manera de llegar a la raspberry será utilizando la IP que el provedor de internet me haya asignado. En mi caso, dicha dirección IP puede variar al antojo del proveedor ya que no tengo contratada una IP fija. La cuestión que se plantea es ¿Cómo conseguir que el dominio apunte contínuamente a la IP que tengo asignada en cada momento? ¿Qué pasa cuando el proveedor de internet me cambia la IP? Let\u0026rsquo;s Encrypt lanza un desafío para obtener un certificado, que normalmente requiere de un acceso por http al puerto 80 de quien inicia el desafío, que en este caso sería la raspberry. Sin embargo, algunos proveedores de internet tienen el puerto 80 reservado y no dejan abrirlo ¿Cómo solventar dicho inconveniente?  La primera cuestión la podríamos resolver creando en Google Domains un Dynamic DNS para nuestro dominio y obteniendo unos credenciales para el mismo.\nA continuación se configuraría en el Home Assistant el módulo de Google Domains para que actualice periódicamente los registros del DNS con la IP que tengamos asignada en cada momento.\n# Example configuration.yaml entry google_domains: domain: subdomain.domain.com username: YOUR_USERNAME password: YOUR_PASSWORD  Sin embargo, de esta forma únicamente se resuelve la primera de las cuestiones. Me gustaría disponer de una misma solución para solventar ambas cuestiones: Cloudflare al rescate!\nCloudflare Cloudflare es una red de entrega de contenido (CDN) que nos va a permitir resolver las dos cuestiones que se plantean al inicio. Por un lado tiene un api que permitirá a la raspberry pi notificar de forma periódica cuál es su dirección IP. Y por otro lado también expone un API que permite realizar un desafío DNS para la obtención del certificado, en lugar del habitual desafío http.\nUna vez registrados en Cloudflare, se accede a la cuenta y se da de alta el dominio propio de Google Domains:\nAl dar de alta el nuevo sitio lo haremos con la siguiente configuración:\n Acceso directo (opción DNS Only) Sin SSL Sin DNSSEC Sin ningún tipo de optimización de javascript  Una vez dado de alta el sitio, habrá que configurar en el dominio de Google Domains los nameserver que se indiquen en Cloudflare:\nCon todo esto, pasaremos a configurar el módulo de Cloudflare en el Home Assistant:\ncloudflare: email: \u0026lt;EMAIL\u0026gt; api_key: !secret cloudflare_globalapikey zone: popishome.com records: - domotic  El api_key se corresponde al Global Api Key y lo obtenemos de la configuración del perfil (My Profile) en Cloudflare:\nCon esta configuración se ha resuelto la primera de las cuestiones. Home Assistant notificará periódicamente la IP a Cloudflare y actualizará los registros DNS consecuentemente.\nPara resolver la segunda cuestión utilizaré un add-on de Home Assistant, concretamente he utilizado NGINX Proxy Manager. He seleccionado este add-on y no el oficial de NGINX, porque me resulta más sencillo de configurar y porque se integra con Cloudflare. Este add-on permite obtener fácilmente certificados de Let\u0026rsquo;s Encrypt y en lugar de pasar el habitual desafío HTTP se puede indicar que sea mediante un desafío DNS. El desafío DNS consiste simplemente en añadir de forma temporal unos registros DNS para que Let\u0026rsquo;s Encrypt pueda comprobar que estamos en posesión del dominio. Para poder añadir estos registros temporales hay que disponer de un token con permisos para editar el DNS en Cloudflare.\nLa generación de un token con los permisos necesarios se hará desde My Profile de Cloudflare:\nUna vez generado el token, desde la pantalla de administración del add-on NGINX Proxy Manager se genera un nuevo certificado:\nYa con el certificado generado, configuramos un nuevo proxy para el Home Assistant:\nY finalmente, configuramos SSL para dicho host, utilizando el certificado que hemos generado anteriormente:\nLo último que queda por realizar, es abrir en el router del proveedor a internet el puerto configurado en el NGINX Proxy Manager para el protocolo HTTPs:\n En mi caso particular he tenido que realizar un paso extra porque estoy utilizando Google WiFi en casa y tengo creada una red interna. He tenido que mapear el puerto de la red \u0026ldquo;externa\u0026rdquo; (la del router del proveedor a internet) y la red \u0026ldquo;interna\u0026rdquo; (la creada por Google WiFi y en la que está conectada la raspberry con el Home Assistant)\n  Quería poner el enlace a Google WiFi pero no lo encuentro. Me he acordado de que era un producto que no se vendía en Europa y me lo trajeron de USA (parece que sigue sin venderse aquí). Sí que he encontrado Nest WiFi que tiene pinta de ser lo mismo pero comercializado bajo la marca Nest.\n Conclusión Mediante el uso de Cloudflare he sido capaz de resolver las 2 cuestiones que se me planteaban al principio. Por un lado se actualiza la IP de la raspberry en los registros DNS del dominio propio. Y por otro lado se obtienen certificados de Let\u0026rsquo;s Encrypt para el dominio propio y se utilizan para establecer una conexión segura. No lo he mencionado hasta el momento, pero la funcionalidad de Cloudflare que he utilizado no tiene coste alguno.\n","date":1603212240,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1603538880,"objectID":"4f160fdaebf819d5e3bf7e24e72a1d5d","permalink":"https://diegocastroviadero.com/post/como-exponer-homeassistant-a-internet/","publishdate":"2020-10-20T16:44:00Z","relpermalink":"/post/como-exponer-homeassistant-a-internet/","section":"post","summary":"En este post explico cómo exponer a internet por https una instalación local de home assistant utilizando un dominio propio.","tags":["home assistant","nginx","letsencrypt","cloudflare","google domains"],"title":"Cómo exponer una instalación casera de Home Assistant a Internet","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n   Parte Título     \rP01 Hardware   \rP02 Sistema Operativo y Docker   \rP03 Cluster K3S   P04 Consumo eléctrico   P05 (proximamente)    Introducción En un post anterior de esta serie ya mencioné la primera disyuntiva a la que me enfrenté: cloud vs. on premise. En ese momento tuve en cuenta los costes de ambas alternativas, aunque la comparativa fue poco precisa, ya que para la opción on premise no tuve en cuenta el coste eléctrico para mantener el cluster encendido. Es por esto que desde entonces he buscado la manera de medir el gasto eléctrico del cluster.\nDesde un principio era totalmente consciente de que el proyecto del cluster me iba a llevar varios meses, y eso teniendo únicamente en cuenta únicamente el tiempo de investigación, prueba y aprendizaje. Si evoluciona como espero, el cluster se convertirá en una pieza central y tendrá un uso continuado. Mi intención es utilizarlo para ejecutar en él algunas aplicaciones que uso habitualmente y que tengo desperdigadas en varias raspberry por la casa, como por ejemplo el Home Assistant que se menciona en este post.\nTeniendo en cuenta que el cluster va a estar en funcionamiento ininterrumpidamente, considero que sería muy interesante medir el consumo eléctrico y calcular su coste. De esta forma podría hacer una comparativa más precisa entre el coste de un cluster en el cloud y el coste de este cluster.\n¿Cómo medir el consumo eléctrico? Para medir el consumo del cluster me he decantado por un Sonoff Pow R2. Lo he colocado \u0026ldquo;antes\u0026rdquo; de la regleta que alimenta todos los elementos del cluster. De esta forma toda la corriente necesaria para hacer funcionar el cluster: luces, ventilación, raspberry, switch\u0026hellip; pasará a través del Sonoff y podrá ser contabilizada de forma global.\nPara acoplar el Sonoff a la caja del cluster he diseñado unas piezas y las he imprimido con mi impresora 3D. He decidido inicialmente dejar el Sonoff en el exterior para tener una mejor cobertura WiFi ¿La caja del cluster actuaría como una caja Faraday? En este caso he preferido ser pruedente y dejarlo incialmente por fuera, aunque no sea lo más estético. En un futuro quizás me anime a rediseñar las piezas para dejar el Sonoff en el interior de la caja del cluster.\nDe nada sirve medir el consumo si no se realiza un registro del mismo. Para realizar el registro del consumo eléctrico contabilizado por el Sonoff he aprovechado una instancia de Home Assistant que tengo para la domótica de mi casa. De esta forma puedo disponer fácilmente de un panel para visualizar dicho consumo. En este post no voy a explicar cómo instalar Home Assistant, aunque sí que voy a describir algunas de las configuraciones que he tenido que cambiar.\nSonoff Pow R2 Este es un dispositivo barato que podría definirse como un interruptor \u0026ldquo;inteligente\u0026rdquo; que puede controlarse via WiFi y que permite medir el consumo eléctrico. En este caso no lo utilizo como interruptor, sino únicamente lo uso para medir el consumo. La forma de \u0026ldquo;anular\u0026rdquo; el interruptor (con software) es configurarlo de tal forma que esté siempre \u0026ldquo;encendido\u0026rdquo;. Otra forma más invasiva de conserguirlo sería desoldar el relay y puentearlo.\nSonoff proporciona una aplicación móvil a través de la cual se pueden controlar los diferentes dispositivos de la marca, programarlos y visualizar la información que generan. Para que todo esto sea posible, la información generada por los dispositivos viaja hasta los servidores de la empresa y desde ahí a los dispositivos móviles.\nSin embargo, ni me interesa que mis datos pasen por un servidor de un tercero, ni tengo interés en usar una aplicación móvil adicional, porque lo que quiero es integrarlo con Home Assistant. La ventaja de Home Assistant es que me permite integrar dispositivos de distintos fabricantes, tener toda la domótica centralizada y utilizar una única aplicación para controlar todo. En este caso, tiene la ventaja añadida de que los datos no pasan por ningún servidor ajeno, se quedan en casa.\n¿Cómo integrar Sonoff con Home Assistant? \rESPHome es la respuesta!\nESPHome es un sistema que permite controlar de forma remota dispositivos ESP8266 y ESP32. Y casualmente los dispositivos Sonoff llevan un chip ESP8266. Realmente no es casualidad, esto es algo que investigué antes de decidirme a comprar el Sonoff Pow R2. Al descubrir ESPHome y lo fácil que era integrarlo con Home Assistant, la decisión estaba clara.\nLa integración de ESPHome con Home Assistant es muy sencilla y consiste en instalar un add-on en Home Assistant. La instalación del add-on es muy sencilla pero he tenido problemas de acceso a la interfaz a través de NGINX, debidos al uso de WebSockets que hace el add-on de ESPHome. Para solucionarlo he incluído la siguiente configuración en NGINX.\nProgramación del Sonoff Para poder controlar un dispositivo con el chip ESP8266 mediante ESPHome hay que flashear en el chip un binario con el código de ESPHome. Para flashear dicho binario he utilizado esphome-flasher. En imprescindible un adaptador serie USB a TTL para poder conectar el dispositivo a un PC y flashear el código. Yo he utilizado un adaptador CH340G. Los drivers de los adaptadores se encuentran accesibles aquí.\n¿Cómo obtenemos el binario con el código a flashear? Esto es una tarea muy sencilla, gracias a ESPHome que lo simplifica al máximo. Simplemente hay que generar un fichero yaml con la configuración y comportamiento que queramos que tenga el dispositivo. ESPHome se encarga de generar un binario con el código correspondiente al contenido de dicho fichero yaml.\nEste es el fichero yaml que he utilizado en este caso:\nesphome: name: rpicluster_power platform: ESP8266 board: esp01_1m # WiFi connection wifi: ssid: !secret wifi_ssid password: !secret wifi_password # Enable fallback hotspot (captive portal) in case wifi connection fails ap: ssid: \u0026quot;Rpicluster Sonoff POW R2\u0026quot; password: \u0026quot;rpiclustersonoffpowr2\u0026quot; # Enable logging logger: baud_rate: 0 # Enable Home Assistant API api: # Enable over-the-air updates ota: # Enable Web server web_server: port: 80 uart: rx_pin: RX baud_rate: 4800 sensor: - platform: wifi_signal name: \u0026quot;RPI Cluster WiFi Signal\u0026quot; update_interval: 15s icon: mdi:wifi - platform: uptime name: \u0026quot;RPI Cluster Uptime\u0026quot; # Power sensor - platform: cse7766 update_interval: 5s # Current sensor current: name: \u0026quot;RPI Cluster Current\u0026quot; icon: mdi:current-ac unit_of_measurement: A accuracy_decimals: 3 # Voltage sensor voltage: name: \u0026quot;RPI Cluster Voltage\u0026quot; icon: mdi:flash unit_of_measurement: V accuracy_decimals: 1 # Power sensor power: name: \u0026quot;RPI Cluster Power\u0026quot; icon: mdi:gauge unit_of_measurement: W accuracy_decimals: 0 id: rpiclusterpower - platform: total_daily_energy name: \u0026quot;RPI Cluster Daily Energy\u0026quot; power_id: rpiclusterpower filters: - multiply: 0.001 unit_of_measurement: kWh icon: mdi:chart-bar time: - platform: homeassistant id: homeassistant_time interval: - interval: 10s then: if: condition: wifi.connected: then: - light.turn_on: led else: - light.turn_off: led binary_sensor: # Binary sensor for the button press - platform: gpio name: \u0026quot;RPI Cluster Power Button\u0026quot; pin: number: GPIO0 mode: INPUT_PULLUP inverted: true on_press: - switch.toggle: relay - platform: status name: \u0026quot;RPI Cluster Status\u0026quot; switch: - platform: gpio name: \u0026quot;RPI Cluster Sonoff Relay\u0026quot; id: relay pin: GPIO12 restore_mode: RESTORE_DEFAULT_ON - platform: restart name: \u0026quot;RPI Cluster Sonoff Restart\u0026quot; output: - platform: esp8266_pwm id: pow_blue_led pin: number: GPIO13 inverted: True light: - platform: monochromatic name: \u0026quot;RPI Cluster POW Blue LED\u0026quot; output: pow_blue_led id: led text_sensor: - platform: version name: \u0026quot;RPI Cluster POW Version\u0026quot;  La información de los pines de entrada/salida del sonoff se encuentra en la documentación.\nQuiero destacar que el sonoff únicamente hay que conectarlo al pc para flashearlo la primera vez. En el yaml anterior se habilita OTA (over-the-air), lo que permite actualizar el código a través de la conexión WiFi, sin necesidad de volver a abrir el dispositivo y desmontarlo de donde estuviera.\nPanel de control Gracias a la integración de ESPHome con Home Assistant es muy sencillo crear un panel de control como el que se ve en la siguiente imagen:\nEn el panel anterior se dispone de:\n Consumo actual  Corriente Potencia Voltaje   Estado  Tiempo en marcha (\rver template en anexo ) Versión de ESPHome en el sonoff   Histórico de consumo Consumo diario Estado y control del led azul  Este led lo utilizo para representar la conectividad a la WiFi (encendido significa conectado)   Estado y control del relay   El pico de consumo de más de 1500W no se corresponde a un uso normal del cluster. Se corresonde a unas pruebas de estuve realizando para calibrar el Sonoff. La calibración del Sonoff queda fuera del ámbito de este post y lo explicaré en otro momento.\n Conclusión El principal objetivo de construir este cluster era didáctico. A día de hoy no tengo claro si esta va a ser su única finalidad o si, una vez terminado, lo voy a utilizar con otros fines, puesto que ideas no me faltan. Conocer el consumo eléctrico y su consiguiente coste económico es una variable que voy a tener muy en cuenta a la hora de decidir el uso del cluster a medio-largo plazo.\nAnexo Configuración NGINX para WebSockets de ESPHome location /api/hassio_ingress { resolver 127.0.0.11 valid=30s; # Home Assistant IP set $upstream_app 192.168.86.4; # Home Assistant Internal Port set $upstream_port 8123; # Home Assistant Internal Protocol set $upstream_proto http; proxy_pass $upstream_proto://$upstream_app:$upstream_port; # Home Assistant External Host:Port proxy_set_header Host $host:9443; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026quot;upgrade\u0026quot;; }  Drivers adaptador USB a TTL  \rCH340G \rCP210X \rPL2303  Template para el tiempo en marcha Por defecto el tiempo que lleva encendido el sonoff se envía en segundos. Este dispositivo está pensado para estar contínuamente encendido enviando las lecturas, independientemente de si el cluster está en marcha o no. Por este motivo no tiene mucho sentido visualizar en el panel esta información en crudo. Para transformar este dato en otro que aporte más valor he creado el siguiente template en el Home Assistant:\nsensor: - platform: template sensors: rpi_cluster_pow_uptime_readable: friendly_name: \u0026quot;RPI Cluster Uptime\u0026quot; icon_template: \u0026quot;mdi:timer\u0026quot; value_template: \u0026gt;- {% set uptime = states.sensor.rpi_cluster_pow_uptime.state | int %} {% set days = (uptime / 86400) | int %} {%- if days \u0026gt; 0 -%} {{ days }} days, {{ (uptime - (days * 86400)) | int | timestamp_custom('%H:%M:%S', false) }} {%- else -%} {{ uptime | int | timestamp_custom('%H:%M:%S', false) }} {%- endif -%}  Si lleva más de un día encendido, se visualizará el número de días que lleva encendido junto con las horas, minutos y segundos. Si lleva menos de un día, simplemente se visualizarán las horas, minutos y segundos.\n Este template podría mejorarse aún más teniendo en cuenta meses y años\n Piezas para la caja del cluster Para realizar el diseño de todas las piezas he utilizado OnShape. Todos los diseños que he realizado para la caja son públicos y encuentran disponibles aquí.\nComo se puede ver en las siguientes imágenes, las piezas para albergar el Sonoff no son las únicas que he diseñado para la caja del cluster. También he diseñado una tapa para una de las aberturas traseras y otra tapa para albergar tanto la toma de corriente como la toma de red de todo el cluster:\nEstoy muy contento con el resultado final, la verdad que ha quedado todo muy organizado y con un mínimo de cables:\n","date":1602695340,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1603357020,"objectID":"f7ebc9aee53495c7b974009004bdbc8f","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-iv/","publishdate":"2020-10-14T17:09:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-iv/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta entrega explicaré el mecanismo que utilizo para medir el consumo eléctrico del cluster.","tags":["cluster","raspberry","home assistant","esphome","sonoff"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte IV)","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n   Parte Título     \rP01 Hardware   \rP02 Sistema Operativo y Docker   P03 Cluster K3S   \rP04 Consumo eléctrico   P05 (proximamente)    K3s \rK3s es una distribución de kubernetes certificada que ha sido concebida para el mundo IoT y \rEdge Computing. K3s ha sido optimizada para ARM (ARM64 y ARMv7) y esto es lo que ha hecho decidirme por esta distribución para instalar kubernetes en el cluster de raspberry pi. En K3s se han reducido las dependencias al máximo, haciendo posible que se distribuya como un único binario de menos de 40 MB. La reducción de dependencias también ha supuesto una simplificación del proceso de instalación.\nInstalación La instalación es muy sencilla, ya que el equipo de K3s ha creado un playbook de Ansible para realizarla. Yo me he basado en dicho playbook y he realizado alguna pequeña adaptación/mejora.\nLo primero que he realizado ha sido adaptar el fichero de inventario a las necesidades del playbook, para ello he definido los grupos:\n k3s_master: que incluye el nodo maestro k3s_node: que incluye los nodos esclavos k3s_cluster: que incluye todos los miembros del cluster  [k3s_master:children] rpicluster01 [k3s_node:children] rpicluster02 rpicluster03 rpicluster04 rpicluster05 [k3s_cluster:children] k3s_master k3s_node  (se puede ver el fichero completo aquí)\nA continuación se muestra el playbook de instalación:\n- hosts: k3s_cluster gather_facts: true become: true roles: - role: prereq - role: download - role: ubuntu - hosts: k3s_master become: true roles: - role: k3s/master - hosts: k3s_node become: true roles: - role: k3s/node  Como se puede observar, se basa en el uso de roles. Existen 3 roles de preparación (prereq, download y ubuntu) que se ejecutarán sobre todos los miembros del cluster. Estos roles se encargan de activar algunas configuraciones necesarias en el sistema operativo, así como de realizar la descarga del binario en función de la arquitectura sobre la que se esté realizando la instalación.\nAdemás existe un role que se ejecutará sobre el nodo maestro y otro que se ejecutará sobre los nodos esclavos. Estos roles son los que crean el cluster K3s propiamente dicho.\n(se puede ver el playbook completo aquí)\nConclusión Gracias al equipo de desarrollo de K3s, que nos proporciona un playbook de Ansible, se puede crear un cluster de kubernetes de una manera muy sencilla.\n","date":1602651600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1602694800,"objectID":"6b0ec67041bc26f66887535171d45038","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-iii/","publishdate":"2020-10-14T05:00:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-iii/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta tercera entrega explico cómo montar un cluster k3s.","tags":["cluster","raspberry","docker","k3s"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte III)","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n   Parte Título     \rP01 Hardware   P02 Sistema Operativo y Docker   \rP03 Cluster K3S   \rP04 Consumo eléctrico   P05 (proximamente)    Sistema Operativo Una vez que todo el hardware está montado la siguiente decisión a tomar es qué sistema operativo instalar en las Raspberry. En el momento de tomar la decisión barajaba 3 opciones:\n Raspbian Hypriot Ubuntu  Raspbian es la distribución oficial para raspberry, y sería una buena elección. Sin embargo, no me he decantado por esta opción, y la razón principal es que en el momento de tomar la decisión no había una versión final de 64 bits (estaba en beta).\nHypriot es una distribución que desconocía totalmente y que viene con docker preinstalado, lo cual simplificaría el proceso de instalación y supondría un ahorro de tiempo. Tampoco me he decidido por esta opción, y el motivo es el mismo que con Raspbian, no existe una versión de 64 bits.\nTras haber descartado las dos distribuciones anteriores me entró la duda de si mi idea inicial de instalar una distribución de 64 bits era una buena idea. Inicialmente pensaba que con una distribución de 32 bits no podría aprovechar los 8 GB de RAM de las raspberry y de ahí que buscase una distribución de 64 bits. Tras investigar un poco, me di cuenta de que esto no era cierto del todo, con una distribución de 32 bits sí que se aprovecharían los 8 GB de RAM. Un mismo proceso del sistema operativo podría usar como mucho 4 GB de RAM, pero entre varios procesos se podrían consumir los 8 GB. Aún así, mantuve mi idea inicial de instalar una distribución de 64 bits, creo que no tiene sentido a día de hoy comenzar un proyecto optando por 32 bits, aunque esta elección traiga ciertas \u0026ldquo;ventajas\u0026rdquo; inicialmente.\nFinalmente descubrí que Ubuntu tiene distribuciones para ARM y que estas pueden ser de 64 bits. Así que - \u0026ldquo;Señores, ¡Ya tenemos caballo ganador!\u0026rdquo;.\nCon el sistema operativo elegido lo siguiente era:\n flashear las 5 tarjetas de memoria actualizar y realizar ciertas configuraciones en las 5 raspberry instalar Docker en las 5 raspberry  En estos momentos me arrepentí un poco de haber comprado 5 raspberry porque todo lo que fuese a hacer lo tenía que repetir 5 veces. Si tienes claro el proceso, es cuestión de seguirlo a pies juntillas y repetirlo las veces que sea necesario. El problema viene cuando el proceso no está claramente definido, y con cada repetición se va refinando el mismo. Este \u0026ldquo;ir refinando el proceso a medida que lo vas repitiendo\u0026rdquo; no debería ser algo problemático. El problema radica en mi persona y mi obsesión con algunas cosas, y en este caso mi obsesión no me permitiría sentirme cómodo sabiendo que no he ejecutado el mismo proceso en todas las raspberry. Si cuando estoy en la última raspberry me doy cuenta de que sería mejor hacer algo de forma diferente, me vería obligado a volver a hacerlo en todas las raspberry. Aquí es donde la situación podría descontrolarse y llevarme muchísimo más tiempo del necesario con la única ventaja de tener todas las rapberry exactamente iguales.\nAntes de lanzarme a configurar las raspberry busqué la forma de automatizar todo el proceso de configuración, lo cual me permitiría dormir tranquilo sabiendo que todas las raspberry son almas gemelas sin tener que repetir manualmente el proceso de configuración por enésima vez sobre la oveja negra del rebaño. Y la búsqueda fue fructífera, me topé con Cloud-Init y con Ansible.\nCloud-Init Cloud-Init es una tecnología que permite inicializar una instancia y que viene de caja con Ubuntu. Cloud-Init detecta si es el primer arranque del sistema y si es el caso entra en acción permitiendo configurar: usuarios, claves ssh, particiones de disco, configuración de red, etc. Cloud-Init puede obtener las acciones que tiene que ejecutar del propio disco de la instacia o podría obtenerlo a través de la red.\nEn mi caso, las acciones a actualizar las obtiene del propio disco: una vez flasheada la tarjeta SD copio un par de ficheros en la tarjeta con las configuraciones a realizar. Concretamente utilizo cloud-init para:\n actualizar los paquetes del sistema establecer el nombre de la instancia configurar el DNS desactivar la creación del usuario por defecto del sistema operativo crear un usuario específico establecer una clave SSH para el usuario deshabilitar el acceso al sistema con contraseña configuración de una ip fija instalación de paquetes adicionales: curl, vim, git y aptitude  Este es un ejemplo de fichero de configuración de cloud-init de uno de los nodos del cluster:\n#cloud-config preserve_hostname: false hostname: rpicluster01 fqdn: rpicluster01.test package_update: true package_upgrade: true package_reboot_if_required: true manage_resolv_conf: true resolv_conf: nameservers: ['8.8.4.4', '8.8.8.8'] users: ## Disable creation of default user #- default ## Create user - name: rpicluster homedir: /home/rpicluster lock_passwd: true shell: /bin/bash # Generate key with command: ssh-keygen -t rsa -b 4096 -C \u0026quot;your_email@example.com\u0026quot; ssh_authorized_keys: - ************************************************************************************** sudo: - ALL=(ALL) NOPASSWD:ALL ## Disable password authentication with the SSH daemon ssh_pwauth: false ## Install additional packages on first boot packages: - curl - vim - git - aptitude final_message: \u0026quot;The system is finally up, after $UPTIME seconds\u0026quot;  La configuración de red se establece en otro fichero diferente que tiene la siguiente pinta:\n# This file contains a netplan-compatible configuration which cloud-init # will apply on first-boot. Please refer to the cloud-init documentation and # the netplan reference for full details: # # https://cloudinit.readthedocs.io/ # https://netplan.io/reference # # Some additional examples are commented out below version: 2 ethernets: eth0: dhcp4: false addresses: [192.168.86.51/24] gateway4: 192.168.86.1 mtu: 1500 nameservers: addresses: [8.8.4.4, 8.8.8.8] optional: true #wifis: # wlan0: # dhcp4: true # optional: true # access-points: # myhomewifi: # password: \u0026quot;S3kr1t\u0026quot; # myworkwifi: # password: \u0026quot;correct battery horse staple\u0026quot; # workssid: # auth: # key-management: eap # method: peap # identity: \u0026quot;me@example.com\u0026quot; # password: \u0026quot;passw0rd\u0026quot; # ca-certificate: /etc/my_ca.pem  Para flashear la imagen del sistema operativo en la tarjeta SD utilizo rpiimager. Esta herramienta te provee de una interfaz gráfica muy sencilla en la que en primer lugar se selecciona la imagen que quieres flashear, en segundo lugar se elige dónde la quieres flashear y por último se inicia la grabación. Esta herramienta te evita tener que descargar la imagen del sistema operativo ya que es la propia herramienta quien se encarga de descargarla.\nAl arrancar la raspberry por primera vez cloud-init se activará y ejecutará las acciones anteriores, lo único que hay que hacer es esperar unos minutos. Alguien perspicaz, se habrá dado cuenta que hay dos acciones en la lista anterior que no son iguales para todas las raspberry del cluster: establecer el nombre de la instancia y configurar una ip fija. Esto hace que haya que tener para cada instancia del cluster un fichero de configuración diferente. Y en este punto es donde entra en acción Ansible.\n Aunque se le asigne una ip fija a las raspberry, en el router habrá que reservarla igualmente, ya que podría darse el caso de que mientras está apagado el cluster, se conecte algún dispositivo a la red y se le asigne una de las ips del cluster.\n Ansible Ansible, resumiéndolo mucho, es una herramienta de automatización de tareas. Dado un fichero de inventario, en el que se definen una serie de máquinas; y un fichero de tareas (playbook), en el que se definen una serie de tareas; Ansible se encargará de ejecutar cada una de las tareas en cada una de las máquinas. Con el añadido de que la ejecución de dichas tareas es idempotente, es decir, que si alguna de las tareas ya se ha ejecutado en alguna de dichas máquinas, no la volverá a ejecutar. Esto es una simplificación muy grande de todo el universo de Ansible, pero en este post no quiero entrar en detalles sobre Ansible, sino en explicar lo mínimo para que se entienda de qué forma se ha utilizado esta herramienta para montar el cluster.\nComo he mencionado anteriormente, he utilizado Ansible para la generación de los ficheros de configuración de cloud-init. Y este es un caso de uso un poco especial, puesto que no se ajusta a la descripción anterior sobre el funcionamiento básico de Ansible. Sí que disponemos de un fichero de inventario, pero no utilizamos Ansible para ejecutar ninguna tarea sobre las máquinas del inventario, sino para obtener unos datos sobre dichas máquinas y utilizarlos para generar unos ficheros de configuración en el puesto local.\nEste es un extracto del fichero de inventario:\n[rpicluster01] 192.168.86.51 [rpicluster01:vars] custom_hostname=rpicluster01 [rpicluster02] 192.168.86.52 [rpicluster02:vars] custom_hostname=rpicluster02 [rpicluster03] 192.168.86.53 [rpicluster03:vars] custom_hostname=rpicluster03 [rpicluster04] 192.168.86.54 [rpicluster04:vars] custom_hostname=rpicluster04 [rpicluster05] 192.168.86.55 [rpicluster05:vars] custom_hostname=rpicluster05 [rpicluster:children] rpicluster01 rpicluster02 rpicluster03 rpicluster04 rpicluster05  En este caso hemos definido el inventario en un fichero en formato INI. Se puede ver que se han definido varios grupos. Hay un grupo con un solo elemento para cada una de las máquinas del cluster y así poder hacer referencia a una máquina concreta:\n rpicluster01 rpicluster02 rpicluster03 rpicluster04 rpicluster05  También hay un grupo que está compuesto por todas las máquinas del cluster, para poder hacer referencia a todo el cluster:\n rpicluster  Para cada una de las máquinas se define una propiedad custom_hostname que contiene el nombre de la máquina.\n(se puede ver el fichero completo aquí)\nA continuación se muestra el playbook de ansible que genera los ficheros de configuración de cloud-init para las máquinas del cluster:\n--- - hosts: rpicluster gather_facts: false tasks: - name: create directories file: path: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}\u0026quot; state: directory delegate_to: localhost - name: generate user-data config file from template template: src: template_userdata.j2 dest: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}/user-data\u0026quot; delegate_to: localhost - name: generate network-config file from template template: src: template_networkconfig.j2 dest: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}/network-config\u0026quot; delegate_to: localhost  Se definen 3 tareas:\n La tarea 1 se encarga de crear un directorio para cada una de las máquinas del inventario La tarea 2 genera el fichero de configuración user-data a partir de un template La tarea 3 genera el fichero de configuración network-config a partir de un template  (se puede ver el playbook completo aquí)\nCómo instalar Ansible en Windows 10 La manera más fácil de utilizar Ansible en Windows 10 es a través del WLS. Para instalar Ansible he utilizado pip, por lo que el primer paso será instalar pip3 y algunas dependencias necesarias:\nsudo apt install -y python3-pip python3-dev libffi-dev libssl-dev  A continuación se instala Ansible (a nivel del usuario):\npip3 install ansible --user  Por último se actualiza el PATH:\necho 'PATH=$HOME/.local/bin:$PATH' \u0026gt;\u0026gt; ~/.bashrc  Estas son algunas utilidades interesantes que recomiendo tener instaladas para trabajar con Ansible:\npip3 install yamllint ansible-lint molecule  Actualizar Ansible 2.9 a 2.10 Recientemente se ha lanzado la versión 2.10 de Ansible y en esta versión ha habido una reestructuración importante de módulos. Debido a esta reestructuración la actualización no se puede hacer ejecutando un upgrade del paquete ya instalado, sino que hay que desinstalar la versión instalada (la versión 2.9):\npip3 uninstall ansible ansible-base  Y a continuación instalar de nuevo (la última versión, 2.10):\npip3 install ansible --user  Docker Gracias a Ansible, la instalación de Docker en todas las máquinas se ha simplificado al máximo. He encontrado un playbook, que he utilizado casi tal cual, que se encarga de instalar Docker en sistemas debian. Se puede encontrar la versión que he utilizado aquí.\nConclusión Como conclusión he de decir que tanto cloud-init como Ansible han sido dos grandes descubrimientos. Sobre todo Ansible, ya que veo que es una herramienta que puedo empezar a utilizar en mi día a día a nivel profesional.\nLa única pega que le veo a Ansible, es que algunos aspectos no son compatibles con Windows. Actualmente utilizo un Windows 10 y he podido hacer uso de Ansible sin grandes complicaciones a través de WLS. El único inconveniente que me he topado hasta el momento, ha sido a la hora de utilizar Ansible Vault, ya que para ciertas situaciones es necesario modificar los permisos de algunos ficheros, lo cual no es posible en WLS a día de hoy (o al menos yo no he encontrado la manera de hacerlo).\n","date":1601205540,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1602257160,"objectID":"5aa94f4c61de593b99b1deac7a6b87ae","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-ii/","publishdate":"2020-09-27T11:19:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-ii/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta segunda parte explico qué sistema operativo he decidido instalar en los nodos del cluster y cómo instalar Docker en los mismos.","tags":["cluster","raspberry","docker","ubuntu","ansible","cloud-init"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte II)","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar cómo he montado un cluster de Kubernetes utilizando Raspberry Pi y algún ejemplo de uso.\n   Parte Título     P01 Hardware   \rP02 Sistema Operativo y Docker   \rP03 Cluster K3S   \rP04 Consumo eléctrico   P05 (proximamente)    Introducción Kubernetes es una tecnología de orquestación de contenedores que lleva en el mercado ya varios años. Sin embargo, hasta la fecha, no he tenido la oportunidad de \u0026ldquo;jugar\u0026rdquo; con ella. Llevo varios años trabajando intensamente con Docker, y tenía como asignatura pendiente empezar a utilizar algún orquestador de contenedores. Como a nivel profesional no he tenido la ocasión de hacerlo, y como pienso que como mejor se aprende es practicando, nada mejor para aprender Kubernetes, que montarme un cluster Kubernetes desde cero. Quizás llegue un poco tarde, pero creo que es mejor tarde que nunca.\nFinalmente me he decidido por montar un cluster on premise en mi casa. Al principio pensé que lo más sencillo, rápido y barato sería hacerlo en el cloud, pero lo cierto es que me daba mucha pereza. Demasiados proveedores, cada uno con unos servicios gratuitos, con unas condiciones de pago por uso diferentes, en alguno de los cuales ya había consumido dicho uso gratuito, etc.\nAunque montar un cluster on premise suponga un desembolso inicial superior y un mayor esfuerzo, frente a montarlo en el cloud, encuentro al menos dos motivos que han hecho que me decline por esta opción.\nEn primer lugar, considero que montando el cluster on premise me puede simplificar el aprendizaje de los conceptos básicos, ya que no me veré distraído por la terminología y servicios accesorios varios ofrecidos por los proveedores cloud.\nEn segundo lugar, me da mucha tranquilidad saber que si lo apago no consumo nada. Sé que este argumento puede no tener mucho sentido, ya que en el cloud, uno tiene control sobre los servicios que contrata y también podría \u0026ldquo;apagarlo\u0026rdquo; en cualquier momento. La cosa es que el mundo de los proveedores cloud también es nuevo para mí, y el sistema de facturación me parece un poco complejo. Sería otra cosa desconocida adicional a la que enfrentarme. Mi objetivo inicial es aprender Kubernetes, no es conocer como montar un cluster kubernetes en Amazon, Google o Azure y cuánto me van a cobrar por ello. En el pasado ya he tenido algún susto con grandes facturas de proveedores cloud, por creer que estaba haciendo uso de los servicios gratuitos, cuando no era cierto.\nComponentes El cluster está compuesto inicialmente de 5 Raspberry Pi modelo 4b con 8GB de RAM. Esto hace que el cluster disponga de:\n 20 cores a 1'5 GHz 40 GB de memoia RAM  Cada Raspberry tiene una tarjeta de memoria microSD Samsung EVO Plus de 32GB. Este almacenamiento será únicamente para la ejecución del sistema operativo. Inicialmente también lo utilizaré para la persistencia de los contenedores del cluster. Más adelante cuando me adentre en el mundo de los volúmenes persistentes, montaré un mecanismo de persistencia dedicado.\nCon el objetivo de facilizar el montaje del cluster y reducir el número de clables necesarios, he comprado unos módulos HAT PoE que me permiten alimentar las Raspberry por PoE. De esta forma puedo prescindir de los transformadores y los cables USB para alimentar las Raspberry, ya que con el mismo cable ethernet alimento las Raspberry y les proporciono conexión de red.\nPara poder alimentar las Raspberry por PoE he comprado un switch Netgear GS108PP con 8 puertos y con alimentación PoE en todos. Esto me permite tener hasta 7 Raspberry alimentadas y conectadas, ya que uno de los puertos lo utilizo para conectar el switch a la red.\nPara albergar todos los componentes he comprado un armario rack de 19\u0026rdquo; Phasak PHP 2106. El armario tiene 6U de espacio en total que será utilizado de la siguiente forma:\n 1U para una reglega de 8 tomas con interruptor 1U para el switch que va sobre una bandeja 2U para alojar hasta 12 Raspberry Pi 2U libres  Para colocar todas las Raspberry en fila en el armario rack, he imprimido este proyecto, disponible en Thingiverse. Ocupando 2U del rack se pueden tener 12 Raspberry. Cada Raspberry está en una bandeja extraíble, haciendo muy sencillo una sustitución. La mayoría de ejemplos que había visto para apilar Raspberry, lo hacian de tal forma que el recambio de una de ellas implicaría desmontar todo. Este es uno de los pocos que he encontrado que facilita el mantenimiento.\nAntes de poner el cluster en funcionamiento de forma continuada me gustaría tener un mecanismo para medir el consumo del mismo. Tengo pendiente comprar algún dispositivo que me permita medir el consumo y tener algún tipo de histórico para calcular su coste. He hecho una búsqueda rápida y he visto un montón de enchufes baratos que miden el consumo, aunque ninguno me ha convencido. Me gustaría tener una solución que se integre con Home Assistant, que es la solución que tengo en casa para la domótica. Este aspecto queda fuera del ámbito de este post y no me extenderé más en ello.\nConclusión La combinación de estos componentes me permite tener un cluster:\nCompacto El armario rack de 19\u0026rdquo; y 6U es un armario de reducidas dimensiones que puedo colocar en cualquier sitio de la casa.\nVentilado El armario rack dispone de 2 grandes ventiladores en la parte superior. Además cada Raspberry dispone de un ventilador ya que el HAT PoE incluye uno. Creo que es ventilación suficiente para dejar el cluster encendido de continuo sin miedo a que se sobrecaliente.\nOrdenado Los HAT PoE han ayudado mucho a que el armario no tenga demasiados cables en su interior y a que la regleta tenga más tomas disponibles para su uso.\nIluminado El armario rack dispone también de iluminación led, esto me da libertad para poder situar el armario rack en cualquier punto de la casa y poder hacer un mantenimiento del mismo sin problemas de falta de luz.\nExtensible Gracias al proyecto de thingiverse puedo colocar hasta 12 Rasperry ocupando 2U del armario. Con las 2U que me quedan libres podría:\n Colocar otras 12 raspberry pi Colocar algún dispositivo SAI Dedicarlo a almacenamiento etc  BOM  5x Raspberry Pi modelo 4b con 8GB de RAM 5x Samsung EVO Plus de 32GB 5x HAT PoE 1x Netgear GS108PP 1x Phasak PHP 2106 1x Reglega de 8 tomas con interruptor 1x Bandeja 1x Cables de red de 25cm 1x Tornillos y tuercas para armario rack 1x Tornillos M2.5 para Raspberry Pi 2x Varilla roscada M4 de 1m (comprado en ferretería) 8x Tuercas M4 (comprado en ferretería)  ","date":1600443060,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1601197920,"objectID":"ea7e4207f32ed47280f9cd6d665567af","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-i/","publishdate":"2020-09-18T15:31:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-i/","section":"post","summary":"En esta serie de posts explicaré cómo he montado un cluster de Kubernetes con Raspberry Pi. En esta primera parte explico cómo está configurado el cluster en cuanto a hardware se refiere.","tags":["cluster","raspberry"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte I)","type":"post"},{"authors":[],"categories":[],"content":"Sistema de automatización de fichajes  Objetivo El principal objetivo es simplificar el proceso de fichajes de una empresa\nUn objetivo secundario es el de utilizar tecnologías para seguir creciendo como profesional de la Informática.\n ## Contexto - Recordar cada una de las acciones a realizar - Para ciertas acciones hay que escribir un texto adicional - Login requerido para realizar cada una de las acciones - Intranet no adaptada al uso desde el móvil    ## Requisitos - Fichaje lo más fiel posible a la realidad - El usuario no tiene que recordar realizar ninguna acción - Las acciones manuales por parte del usuario serán muy sencillas - Se tendrán en cuenta los fichajes realizados directamente en la intranet    Solución La solución desarrollada es un chatbot de telegram:\nTimeHammerBot\nhttps://t.me/TimeHammerBot\nLo único necesario para poder utilizarla será disponer de un smartphone y tener instalada la aplicación de mensajería Telegram. También compatible con la versión web de Telegram\n ## Funcionamiento #### Trabajador 1. Registro en el chatbot - Hora de inicio y final de la jornada - Hora de inicio y final de la comida - Lugar de trabajo 1. Se olvida de volver a fichar    ## Funcionamiento #### Chatbot 1. Llegada la hora de una determinada acción - Comprueba el estado del trabajador - Si procede, notifica al trabajador 1. El trabajador recibe la notificación - Confirma/Postpone/Cancela la acción 2. El chatbot recibe la respuesta - Ejecuta la acción en la intranet - Se queda a la espera - Ignora la acción hasta el día siguiente    ## Ejemplo 1 Trabajador  lunes | comienzo jornada | 8:00 - A las 8:00 recibirá un mensaje preguntándole si ya ha comenzado a trabajar - Debajo del mensaje aparecerán una serie de botones: Sí, +5m, +10m, +15m, +20m, No - Con solo pulsar un botón el chatbot actuará en consecuencia    ## Ejemplo 2 Trabajador  vienes | comienzo jornada | 8:00 - Comienza a trabajar antes de lo normal - Fichaje manual en la intranet a las 7:30 - A las 8:00 el chatbot comprobará el estado y verá que no tiene nada que notificar    Extra I El chatbot busca molestar lo menos posible\n Fines de semana Festivos  Ciudad de trabajo   Vacaciones   Extra II No se persiste la contraseña de los usuarios, se guardan en memoria.\nSi se reinicia el contenedor que tiene en memoria las contraseñas, se enviará un mensaje a los trabajadores para que vuelvan a introducir su contraseña.\n DEMO  ## Objetivos cumplidos - Todos los fichajes requieren de una confirmación y son fieles a la realidad - El usuario ya no tiene que recordar realizar una determinada acción - La única acción manual del usuario consiste en pulsar un botón- El usuario ya no tiene que conectarse a una intranet - Al recuperar siempre el estado del usuario de la intranet, se posibilita combinar el uso de ambos sistemas para situaciones excepcionales    Stack tecnológico  Java Quarkus Docker Telegram Bots Kafka PostgreSQL   Event Driven Architecture I  Event Driven Architecture II  Roadmap I Reducción de llamadas a Comunytek En la versión actual se realizan:\n30 * 12 + 6 * 12 + 4 = 436 llamadas/usuario/día\nCon la versión mejorada se realizarían:\n3 llamadas/acción * 4 acciones/día/usuario = 12 llamadas/usuario/día\n Roadmap II Kubernetes I  Roadmap II Kubernetes II  Roadmap II Kubernetes III  Roadmap III  Anular el registro Modificar la configuración Mejorar validaciones en el registro Añadir tests Tunear configuración Kafka Añadir monitorización de módulos NLP Modulo de administración   ## Chatbots I - Los chatbots son una herramienta mucho potencial que permite aplicar un nuevo enfoque para resolver ciertos problemas - Los usuarios están cada vez más acostumbrados a las aplicaciones de mensajería - Tienen peor fama de la que se merecen porque muchos de los que se hacen llamar chatbots, hacen un mal (o nulo) procesamiento del lenguaje natural y realmente se trata de una sucesión de condiciones lógicas que ejecutan ciertas acciones    ## Chatbots II - Con este proyecto se muestra un **enfoque diferente** de chatbot, basado en el uso de **comandos**. Que mediante el uso de diferentes **teclados** que se **adaptan** al tipo de respuesta que esperas del usuario, **mejora** mucho la **usabilidad**    Caso de Uso Nuevo canal de comunicación para la realización de guardias\n","date":1597384200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599290520,"objectID":"0fce65b41a51745a77269db256dfe812","permalink":"https://diegocastroviadero.com/slides/timehammer/","publishdate":"2020-08-14T05:50:00Z","relpermalink":"/slides/timehammer/","section":"slides","summary":"Sistema de automatización de fichajes","tags":[],"title":"TimeHammer","type":"slides"},{"authors":null,"categories":null,"content":"Este es un proyecto personal en el que llevo trabajando desde comienzos del 2020, poco antes del confinamiento por la COVID-19. Consiste en un sistema que permite recordar y simplificar la realización de los fichajes en una empresa.\nSe trata de TimeHammerBot un chatbot de Telegram en el cual el trabajador se registra indicando su lugar y horario habitual de trabajo. Una vez registrado, el chatbot se encargará de recordarle los momentos en los que se debe realizar un fichaje. No sólo se trata de recordatorios en los diferentes momentos de fichaje, sino que el chatbot propone una serie de botones integrados en los mensajes de recordatorio, que al ser pulsados ejecutan la acción de fichar.\nSe ha desarrollado una arquitectura orientada a eventos EDA. El proyecto se ha dividido en diversos módulos, cada uno con una responsabilidad, que se comunican entre si mediante el envío de mensajes. Estos mensajes representan los diferentes eventos que desencadenan la lógica de negocio.\nPara el desarrollo se ha utilizado Quarkus, que es un stack basado en java que posibilita la compilación a código nativo. Quarkus permite tanto la programación imperativa como la reactiva. En este proyecto se ha optado por la programación reactiva.\nPara el envío de los mensajes se ha utilizado Kafka puesto que la integración con Quarkus es muy sencilla.\nPara la ejecución en producción se utiliza Docker. Cada uno de los módulos que componen el proyecto tiene una imagen de Docker asociada. En el entorno de producción se ejecutan contenedores de dichas imágenes. Actualmente son se utiliza ningún orquestador de contenedores, directamente se están arrancando con docker-compose. El siguiente paso planificado es la utilización de kubernetes como orquestador de contenedores.\n","date":1597294800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599290280,"objectID":"915e32669415332108040900e6a5c2dc","permalink":"https://diegocastroviadero.com/project/timehammer/","publishdate":"2020-08-13T05:00:00Z","relpermalink":"/project/timehammer/","section":"project","summary":"Sistema de automatización de fichajes","tags":["Java","Quarkus","EDA","Kafka","Docker"],"title":"TimeHammer","type":"project"},{"authors":null,"categories":null,"content":"Contexto En el año 2019 hubo un cambio de ley que obliga a todas las empresas de España a proporcionar información sobre la jornada laboral de sus trabajadores, lo que comunmente conocemos como fichajes.\nMi empresa se ha adaptado al cambio de legislación añadiendo una nueva sección en la intranet para que cada empleado pueda registrar la jornada laboral. El enfoque que ha seguido mi empresa es el fichaje \u0026ldquo;en tiempo real\u0026rdquo;, es decir, se toma el momento en el que se están registrando las acciones como el momento en el que las realizas. Esto obliga a fichar en el momento real en el que empiezas a trabajar, en el que comienzas a comer, en el que terminas de comer\u0026hellip; No existe ninguna posibilidad de corrección por parte de los trabajadores, si se olvida registrar alguna de las acciones hay que escribir un email al responsable para indicarlo.\nEste enfoque de \u0026ldquo;tiempo real\u0026rdquo; no es el único posible, he visto otras empresas que también proporcionan un apartado en su intranet, pero que permiten hacer el fichaje \u0026ldquo;en diferido\u0026rdquo;.\nCuestiones a parte serían si estas implementaciones cumplen con la ley o qué responsabilidades tiene el trabajador o qué pasaría si se hace una inspección y los fichajes del trabajador no son correctos.\nProblema La solución tomada por mi empresa no es una solución pensada para el trabajador que sea cómoda de usar, todo lo contrario:\n El trabajador tiene que recordar todas las acciones que tiene que realizar Para ciertas acciones el trabajador tiene no sólo que realizar la acción, sino que tiene que escribir un texto válido para dicha acción Para realizar cada una de las acciones el trabajador tiene que acceder a la intranet, teniendo que introducir sus credenciales Algunas de las acciones se realizan desde sitios donde no hay un ordenador, por lo que hay que acceder a la intranet desde el móvil cuando la intranet no está adaptada para ello. Los menús son muy pequeños y es difícil llegar a la zona de fichajes  Objetivo Me he propuesto simplificar todo este proceso de tal forma que los fichajes se realicen de una manera sencilla, y lo más fieles posible a la realidad. Además utilizaré tecnologías que me permitan seguir desarrollándome como profesional de la Informática.\nRequisitos Estos son los requisitos funcionales que guiarán el planteamiento y desarrollo de la solución:\n Fichaje lo más fiel posible a la realidad Las acciones manuales por parte del usuario serán muy sencillas Se tendrán en cuenta los fichajes realizados directamente en la intranet  Solución La solución desarrollada es un chatbot de telegram: TimeHammerBot. Lo único necesario para podeer utilizarla será disponer de un smartphone y tener instalada la aplicación de mensajería Telegram.\nFuncionamiento El trabajador se registrará en el chatbot TimeHammerBot de Telegram. Para ello tendrá que indicar la empresa en la que trabaja, los credenciales para acceder a la intranet donde se realiza el fichaje manual y los horarios habituales: hora de comienzo y fin de la jornada laboral y hora de comienzo y fin de la comida (para cada día de la semana). Una vez realizado el registro podrá olvidarse de volver a acceder a la intranet para realizar un fichaje. A partir de ese momento será el chatbot quien le recuerde a las horas configuradas, la realización de las acciones pertinentes. Además junto con cada recordatorio, se proporcionarán una serie de botones que permitirán confirmar la realización de dichas acciones.\nPor ejemplo, si el trabajador ha indicado que los lunes suele comenzar la jornada laboral a las 8:00, a esa hora recibirá un mensaje en Telegram preguntándole si ya ha comenzado a trabajar. Debajo del mensaje aparecerán una serie de botones: \u0026ldquo;Sí\u0026rdquo;, \u0026ldquo;+5m\u0026rdquo;, \u0026ldquo;+10m\u0026rdquo;, \u0026ldquo;+15m\u0026rdquo;, \u0026ldquo;+20m\u0026rdquo;, \u0026ldquo;No\u0026rdquo;. Al pulsar el botón \u0026ldquo;Sí\u0026rdquo;, el chatbot se encargará de registrar el inicio de la jornada en la intranet. Al pulsar los botones \u0026ldquo;+Xm\u0026rdquo;, se le pedirá al chatbot que se espere X minutos antes de volver a preguntar. Al pulsar el botón \u0026ldquo;No\u0026rdquo;, se le indicará al chatbot que ese día no se trabaja y hasta el día siguiente no volverá a preguntar nada.\nEl chatbot recuperará de la intranet las vacaciones del trabajador con el objetivo de no molestar durante ese periodo de tiempo. También tendrá en cuenta los días festivos de la ciudad de trabajo del trabajador (motivo por el cual durante el registro hay que indicar la ciudad de trabajo).\nEl chatbot es un mero intermediario, no guardará en ningún momento los fichajes del trabajador. Para conocer el estado de un trabajador lo recuperará de la intranet de la empresa del trabajador. De esta forma se puede combinar el uso del chatbot junto con la realización de ciertas acciones de forma manual. Por ejemplo, si el trabajador ha indicado que los viernes suele comenzar a trabajar a las 8:00, pero excepcionalmente, un viernes comienza su jornada a las 7:30, podrá acceder a la intranet y registrar su fichaje a las 7:30. Cuando sean las 8:00 el chatbot tendrá en cuenta las posibles acciones realizadas manualmente en la intranet antes de preguntar nada. Por lo que en este caso, a las 8:00 el chatbot no preguntará nada al trabajador.\nCon este modelo de funcionamiento se cumplen los 3 requisitos planteados para el proyecto:\n Todos los fichajes requerirán de una confirmación por parte del usuario y serán fieles a la realidad. El usuario se olvida de tener que conectarse a una intranet y registrar una serie de acciones y en su lugar lo único que tiene que hacer es pulsar un botón cuando le llega un mensaje al Telegram. Al no guardar el estado de los trabajadores y recuperarlo siempre de la intranet, se posibilita combinar el uso de ambos sistemas.  Detalles Para conocer más detalles sobre el proyecto puedes acceder aquí\nConclusión Este proyecto ha supuesto un reto bastante interesante por diversos motivos:\n- Llevar un proyecto adelante de principio a fin\n El camino que hay que seguir desde que se tiene una idea hasta que esta se materializa siempre es complicado. A lo largo de este camino existen diversos momentos, en los que lo más fácil es no complicarse y ceder en el intento. Llegar a desplegar en producción una primera versión estable y funcional es motivo suficiente para sentirse orgulloso.\n - Afrontar un nuevo paradigma de programación\n Cambiar la manera de pensar no es trivial. Tareas que considerabas sencillas, de repente, se convierten en complicados rompecabezas. Ante la más mínima complicación es tentador volver a las antiguas costumbres para salir del paso y seguir avanzando. Ha resultado agotador ser fiel a programación reactiva.\n - Nuevas tecnologías\n En este proyecto he utilizado muchas tecnologías desconocidas para mi: Quarkus, Kafka, EDA, compilación nativa de java, imágenes distroless. Para mi siempre es motivador enfrentarme a un nuevo framework, lenguaje, herramienta\u0026hellip; me recuerda a cuando era niño y me regalaban un juguete. Lo que resulta un verdadero reto es realizar un proyecto en el que la gran mayorías de las tecnologías son desconocidas y pasas más tiempo en las páginas de documentación que programando.\n - Ponerse un objetivo y ceñirse a él\n Cuando no tienes a un jefe que te va guiando hacia una meta es complicado no desviarse del camino y resulta muy sencillo irse por las ramas. Más aún cuando tienes un montón de \u0026ldquo;juguetitos\u0026rdquo; nuevos que probar e investigar. Este proyecto no ha sido una excepción, de hecho, la solución final es la tercera que se ha desarrollado desde cero. El proyecto comenzó siendo serverless, basándose en el uso de Firebase. Después se descartó la idea de serverless y pasó a ser un monolito desarrollado en Quarkus. Finalmente se ha mantenido el uso de Quarkus, pero se ha modularizado implementando una arquitectura orientada a eventos.\n Se trata de una primera versión funcional con mucho margen de mejora. He incorporado una gran cantidad de novedades tecnológicas, dada mi experiencia,y hasta el momento no he podido profundizar mucho en ellas para poder tener esta primera versión funcional lo antes posible.\n","date":1580494860,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599288360,"objectID":"f0341a7a0828ccbec3bc1dd1ee582041","permalink":"https://diegocastroviadero.com/post/como-automatizar-los-fichajes-de-mi-empresa/","publishdate":"2020-01-31T18:21:00Z","relpermalink":"/post/como-automatizar-los-fichajes-de-mi-empresa/","section":"post","summary":"En este post explicaré el proyecto que he desarrollado para automatizar los fichajes de mi empresa","tags":["timehammer","chatbot","telegram"],"title":"Cómo he automatizado los fichajes de mi empresa","type":"post"},{"authors":null,"categories":null,"content":"Llevo ya unos meses pensando en renovar los equipos que tengo, bien porque se han quedado desfasados o bien porque quiero ampliar sus funcionalidades y se quedan cortos de recursos. Actualmente dispongo de los siguientes equipos:\n portátil de 13\u0026rsquo; con windows (ligero) portátil de 15\u0026rsquo; con windows (antiguo) portátil de 17\u0026rsquo; con windows (el más potente) raspberry pi con raspbian para la domótica raspberry pi con raspbian para la gestión de finanzas iMac NAS con 2 discos de 2TB en RAID0  El NAS cumple con múltiples funciones:\n almacenamiento de documentos almacenamiento de backups centro multimedia centro de descargas  Para el almacenamiento de documentos utilizo software propio de QNAP que me permite tener sincronizados determinados directorios de un equipo con el NAS. Además tengo la posibilidad de acceder a los mismos, también a través de aplicaciones de QNAP, desde los dispositivos móviles.\nPara la realización de los backups utilizo software propio de QNAP para los equipos Windows, que me permite programar backups de forma periódica. En el caso del iMac, utilizo TimeMachine que lo hace de forma automática y transparente.\nQuien realmente cumple con la función de centro multimedia es Plex Media Server, que está instalado en el NAS, y es quien me permite visualizar el contenido multimedia a través de la Smart TV y de los dispositivos móviles.\nPara la realización de descargas utilizo un cliente BitTorrent instalado en el NAS, que me permite controlarlo desde los dispositivos móviles.\nLo que me gustaría es retirar algunos de los portátiles que tengo junto con el iMac y en su lugar comprarme un buen PC que sea potente y que me permita realizar proyectos personales de Data Science.\nMotivación Una renovación del hardware no tendría por qué llevarme a un replanteamiento de la organización en lo que respecta al almacenamiento. Sin embargo, existen una serie de inconvenientes/mejoras pendientes que llevo arrastrando desde hace un tiempo y que son los verdaderos motivadores del cambio:\n En el iMac tengo configurado el TimeMachine para hacer los backups contra el NAS. Parece que no funciona muy bien, porque desde que lo configuré sale un aviso en el NAS indicando que hay datos erróneos en alguno de los volúmenes. Además, el iMac apenas lo utilizo y es uno de los equipos que quiero jubilar Sólamente uno de los portátiles con Windows tiene configurados los backups y la sincronización de documentos Las Raspberry PI no tienen configurado ningún tipo de backup contra el NAS y, tras haber investigado, QNAP no ofrece demasiadas opciones para Linux Me gustaría tener una única solución tanto de backups como de sincronización de documentos, para todos los sistemas operativos El QNAP funciona muy lento, las opciones de ampliación de sus recursos hardware son muy limitadas y además quiero ampliar sus funcionalidades (ej: añadirle un repositorio de código, poder hacer seguimiento de series y películas con couchpotato o alternativas similares, etc.)  Así que aprovechando que voy a hacer cambios en el hardware y teniendo en cuenta todos los puntos anteriores he decidido hacer un cambio radical.\nQué me gustaría tener Me gustaría tener lo siguiente:\n Tener backups de las Raspberry PI de forma periódica y automática Tener sincronizados con el NAS algunos directorios tanto de equipos Windows como Linux Tener las fotos/videos realizadas con dispositivos móviles guardadas directamente en el NAS de forma automática Tener forma de visualizar a través del móvil las fotografías del NAS Tener forma de visualizar a través del móvil los documentos del NAS Poder montar un volumen del NAS en cualquiera de los portátiles o PC para hacer un backup manual inicial de documentos o fotos Que el NAS haga de forma periódica un backup encriptado a algún cloud Disponer de un cliente de descargas de BitTorrent y poder controlarlo a través del móvil Utilizar Plex Media Server como media center Añadir Radarr, Sonarr y Jackett (o CouchPotato) para el seguimiento de series y películas y descargas automatizadas Tener un repositorio de código git Poder editar documentos, hojas de cálculo, presentaciones, diagramas directamente a través del NAS Aplicación de mensajería privada Aplicación de notas privada Aplicación de calendario privada Poder ampliar libremente los recursos del NAS en un futuro Poder ampliar libremente la funcionalidad del NAS  Alternativas La primera disyuntiva a la que me enfrento es si comprar otro NAS ya montado (al estilo del QNAP) o montármelo yo mismo. La ventaja de comprar uno ya montado es que es \u0026ldquo;enchufar y listo\u0026rdquo;, con el inconveniente de que este tipo de NAS no son demasiado flexibles. La venjata de montarse un NAS es que son totalmente customizables y extensibles, la pega es que requieren de mucho tiempo de investigación, selección de componentes, montaje, configuración y selección de software.\nNAS ya montado He descubierto que Synology tiene mejor integración con linux. He encontrado dos modelos que se ajustan a los requisitos: DS918+ y DS1618+.\nDS918+ Cumple con casi todos los requisitos, la única excepción es la ampliación de recursos. Tiene 4 bahías y la posibilidad de comprar una extensión que permitiría añadir más discos. De serie viene con 4GB de RAM ampliables a 8GB, aunque en algún foro he leído que se le pueden meter 16GB (aunque esto está por comprobar). El procesador tiene 4 cores a 2.1GHz. Tiene una app store de aplicaciones que permite ampliar las funcionalidades del NAS y en caso de no encontrar alguna se podría usar Docker.\nContras:\n el precio 550-600€ el procesador no se puede cambiar, y la RAM sólo se puede ampliar con garantías hasta 8GB las aplicaciones para el móvil no tienen muy buenas valoraciones lo veo justo tanto de procesador como de memoria RAM para las funcionalidades que quiero que ofrezca  DS1618+ Cumple con casi todos los requisitos, la única excepción es la ampliación de recursos. Tiene 6 bahías y la posibilidad de comprar una extensión que permitiría añadir más discos. De serie viene con 4GB de RAM ampliables a 32GB. El procesador tiene 4 cores a 2.1GHz. Tiene una app store de aplicaciones que permite ampliar las funcionalidades del NAS y en caso de no encontrar alguna se podría usar Docker.\nContras:\n el precio 750€ el procesador no se puede cambiar las aplicaciones para el móvil no tienen muy buenas valoraciones lo veo justo de procesador para las funcionalidades que quiero que ofrezca  NAS DIY He estado investigado diferentes alternativas de SO orientados a montar un NAS, y he encontrado que el más usado es FreeNas. También he encontrado otra alternativa que me gusta más: unRaid.\nMuchas de las funcionalidades que quiero cubrir no son ofrecidas directamente por esos SOs, sino que hay que instalar algunos plugins/aplicaciones/contenedores para cubrirlas.\nFreeNas Está basado en FreeBSD y soporta el sistema de ficheros ZFS, que por lo que he leído debe de ser muy bueno y solventa los inconvenientes de RAID.\nContras:\n al estar basado en FreeBSD no tiene soporte nativo de Docker muchas de las funcionalidades se cubren con aplicaciones/plugins que hay que buscar, instalar y configurar, con el esfuerzo que esto conlleva la existencia de aplicaciones móviles para cubrir ciertos requisitos depende de las aplicaciones/plugins que se instalen  unRaid Es un SO basado en Debian, por lo que tiene soporte nativo de Docker. Como se puede deducir de su nombre, no soporta RAID. Lo que hace, es montar un array con todos los discos, dando la visión de que se trata de un único disco. Como mecanismo de protección tiene un sistema de paridad que permitiría el fallo de hasta 2 discos del sistema sin perder los datos. Los datos en los discos se almacenan como en un disco normal, de tal forma que si extraemos un disco del array y lo conectamos a otro dispositivo, podremos ver su contenido.\nContras:\n no es gratuito (pago único de 59-129€, dependiendo del número de discos que se quieran usar) muchas de las funcionalidades se cubren con aplicaciones/plugins que hay que buscar, instalar y configurar, con el esfuerzo que esto conlleva la existencia de aplicaciones móviles para cubrir ciertos requisitos depende de las aplicaciones/plugins que se instalen  Comparativa    Requisito Synology FreeNas unRaid     Tener backups de las Raspberry PI de forma periódica y automática 👍 👍 1 👍 1   Tener sincronizados con el NAS algunos directorios tanto de equipos Windows como Linux 👍 👍 2 👍 2   Tener las fotos/videos realizadas con dispositivos móviles guardadas directamente en el NAS de forma automática 👍 👍 2 👍 2   Tener forma de visualizar a través del móvil las fotografías del NAS 👍 👍 2 3 👍 2 3   Tener forma de visualizar a través del móvil los documentos del NAS 👍 👍 2 👍 2   Poder montar un volumen del NAS en cualquiera de los portátiles o PC para hacer un backup manual inicial de documentos o fotos 👍 👍 👍   Que el NAS haga de forma periódica un backup encriptado a algún cloud 👍 👍 1 👍 1   Disponer de un cliente de descargas de BitTorrent y poder controlarlo a través del móvil 👍 👍 4 👍 5   Utilizar Plex Media Server como media center 👍 👍 4 👍 5   Añadir Radarr, Sonarr y Jackett (o CouchPotato) para el seguimiento de series y películas y descargas automatizadas 👍 ❓ 👍 5   Tener un repositorio de código git 👍 ❓ 👍 5   Poder editar documentos, hojas de cálculo, presentaciones, diagramas directamente a través del NAS 👍 👍 2 👍 2   Aplicación de mensajería privada 👍 👍 2 👍 2   Aplicación de notas privada 👍 👍 2 👍 2   Aplicación de calendario privada 👍 👍 2 👍 2   Poder ampliar libremente los recursos del NAS en un futuro 👎 👍 👍   Poder ampliar libremente la funcionalidad del NAS 👍 👍 6 👍 5    Conclusión Me da miedo de que me pase lo mismo que lo que me ha pasado con el QNAP: que me quede corto de recursos con el paso del tiempo y tener poco margen de maniobra. Se trata de dispositios con un coste elevado, como para tener que verse obligado a cambiarlo por el mero hecho de necesitar más RAM (con la inversión de tiempo que hay que realizar para hacer el cambio).\nDecididamente voy a optar por un NAS DIY, y concretamente por uno con unRaid. He visto unos cuantos análisis y videos de su funcionamiento y me ha gustado bastante. Creo que me convence más la idea de array de discos que la de montar un RAID.\nAdemás que creo que con un mismo equipo puedo cubrir las 2 necesidades: disponer de un PC potente y tener un NAS con más funcionalidades que el actual. En primer lugar compraré el PC que quería comprarme y le instalaré unRaid. Sin me gusta como funciona, le haré una ampliación de hardware. Si por lo que fuera no quedo contento con el resultado, el equipo me vale como PC y volveré a valorar qué hacer para el NAS.\nCuando haya elegido el hardware, montado el equipo, instalado y configurado unRaid, escribié otro post con la situación final.\n  Usando Duplicati \u0026#x21a9;\u0026#xfe0e;\n Usando Nexcloud \u0026#x21a9;\u0026#xfe0e;\n Plex Media Server también permite ver fotos, quiero ver si la gestión de álbumes es similar a google fotos o al menos mejor que la de Nexcloud \u0026#x21a9;\u0026#xfe0e;\n Seguro que se puede pero hay que buscar una aplicación que permita hacerlo \u0026#x21a9;\u0026#xfe0e;\n Con algún contenedor Docker \u0026#x21a9;\u0026#xfe0e;\n Usando los Jail de FreeBSD (no tan extendido como los contenedores Docker) \u0026#x21a9;\u0026#xfe0e;\n   ","date":1580411760,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1580546460,"objectID":"85208c75b05a0a80995309e553ccb18a","permalink":"https://diegocastroviadero.com/post/como-quiero-organizar-mi-almacenamiento/","publishdate":"2020-01-30T19:16:00Z","relpermalink":"/post/como-quiero-organizar-mi-almacenamiento/","section":"post","summary":"Llevo ya un tiempo queriendo hacer una renovación de los equipos que tengo y ya de paso reorganizar mi solución para el almacenamiento. En este post plasmaré cómo me gustaría reorganizarlo todo.","tags":["unRaid"],"title":"Cómo quiero organizar mi almacenamiento","type":"post"},{"authors":null,"categories":null,"content":"Prerequisitos  Tener un dominio en Google Domains Tener un repositorio en GitHub (ej: https://github.com/dicastro/dicastro.github.io)   Este repositorio no tiene por qué ser público, en mi caso se trata de un repositorio privado.\n Pasos 1 - Activa GitHub Pages Para ello en la configuración del repositorio de GitHub:\n Activa GitHub Pages seleccionando una rama desde la cuál se va a servir el contenido Configura un Custom Domain (ej: diegocastroviadero.com)  2 - Apunta el dominio (diegocastroviadero.com) a GitHub Pages Para ello en Google Domains:\n Añade un Custom resource record de tipo A apuntando a GitHub Pages     Nombre Tipo TTL Datos     @ A 1h 185.199.108.153         185.199.109.153         185.199.110.153         185.199.111.153     En este caso @ hace referencia al propio dominio (diegocastroviadero.com)\n  Si las IPs anteriores se han quedado desfasadas, podrás encontrar los valores actualizados aquí\n 3 - Apunta el subdominio www a GitHub Pages Para ello en Google Domains:\n Añade un Custom resource record de tipo CNAME apuntando a la url de GitHub Pages correspondiente al repositorio en cuestión (ej: dicastro.github.io)     Nombre Tipo TTL Datos     @ CNAME 1h dicastro.github.io    4 - Configura HTTPS Para ello en la configuración del repositorio de GitHub:\n Fuerza el uso de HTTPS  Y en Google Domains:\n Añade un Custom resource record de tipo CAA permitiendo la emisión de certificados para el dominio (ej: diegocastroviadero.com) a la entidad emisora de certificados, que en el caso de GitHub es letsencrypt     Nombre Tipo TTL Datos     @ CAA 1h 0 issue \u0026ldquo;letsencrypt.org\u0026rdquo;     En este caso @ hace referencia al propio dominio (diegocastroviadero.com)\n  Para obtener el valor de la columna Datos de la entrada de tipo CAA se puede hacer uso de esta utilidad\n Referencias  https://www.techrepublic.com/article/how-to-add-a-certificate-authority-authorization-record-in-google-domains https://dev.to/trentyang/how-to-setup-google-domain-for-github-pages-1p58  ","date":1580236440,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1580323080,"objectID":"659a0889ce409b1da96f29f1d2c8f4c4","permalink":"https://diegocastroviadero.com/post/como-configurar-un-dominio-propio-de-google-domains-en-github-pages-y-con-https-activado/","publishdate":"2020-01-28T18:34:00Z","relpermalink":"/post/como-configurar-un-dominio-propio-de-google-domains-en-github-pages-y-con-https-activado/","section":"post","summary":"En este post se va a explicar cómo configurar un dominio propio, comprado en Google Domains, en GitHub Pages y cómo activar HTTPS","tags":["google domains","github pages","letsencrypt"],"title":"Cómo configurar un dominio propio de Google Domains en GitHub Pages y con HTTPS activado","type":"post"},{"authors":null,"categories":null,"content":"Este es mi primer post de prueba.\nLa idea es utilizar este blog para escribir artículos relacionados con algunos de mis intereses a modo de base de datos para posteriores consultas. Serán artículos sobre algún tema nuevo que esté investigando o artículos sobre cómo resolver problemas a los que me haya enfrentado.\n","date":1576337940,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1576337940,"objectID":"664bde57003ea7f7bec74d75c0246ab3","permalink":"https://diegocastroviadero.com/post/hola-mundo/","publishdate":"2019-12-14T15:39:00Z","relpermalink":"/post/hola-mundo/","section":"post","summary":"Este es mi primer post","tags":null,"title":"Hola Mundo!","type":"post"},{"authors":null,"categories":null,"content":"Este proyecto ha sido realizado como trabajo final del máster en Data Science \u0026amp; Big Data de la U-TAD.\nPara el desarrollo del proyecto se han realizado las siguientes tareas:\n Estudio del estado del arte en lo que a la detección de objetos se refiere Desarrollo de una implementación de YOLO V3 y de YOLO V3 Lite en python Búsqueda y preparación de un conjunto de imágenes Entrenamiento de varios modelos YOLO con distintas configuraciones y realización de estudio comparativo de los resultados obtenidos Transformación del modelo entrenado para ser explotado en un dispositivo móvil Desarrollo de aplicación android para la explotación del modelo  El proyecto se compone de los siguientes repositorios:\n   Repositorio Descripción     \rtfm Contiene una implementación en python de YOLO V3 y YOLO V3 Lite   \rtfm-android Contiene una aplicación móvil android para la explotación del modelo entrenado mediante el uso de Tensor Flow Lite   \rtfm-doc Contiene la memoria del TFM    Referencias:\n Las imágenes utilizadas para entrenar los modelos han sido obtenidas de kaggle La aplicación móvil se basa en un ejemplo de tensorflow lite La implementación de YOLO V3 es un fork de este repositorio y la implementación de YOLO V3 Lite está basada en este repositorio. Se han unificado ambas implementaciones en una única, se han añadido más opciones de configuración de los modelos y se soportan más formatos de etiquetas de las imágenes  ","date":1569715200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1569715200,"objectID":"d882fc2296783c8bc0aa60fe7de34f77","permalink":"https://diegocastroviadero.com/project/sistema-de-deteccion-automatica-de-baches-en-el-asfalto-a-partir-de-imagenes/","publishdate":"2019-09-29T00:00:00Z","relpermalink":"/project/sistema-de-deteccion-automatica-de-baches-en-el-asfalto-a-partir-de-imagenes/","section":"project","summary":"TFM del máster en Data Science \u0026 Big Data de la U-TAD","tags":["Data Science","Deep Learning","YOLO"],"title":"Sistema de detección automática de baches en el asfalto a partir de imágenes","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"https://diegocastroviadero.com/cv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/cv/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"6880d30a4afb347490251c2f38986b57","permalink":"https://diegocastroviadero.com/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/posts/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://diegocastroviadero.com/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]