[{"authors":["admin"],"categories":null,"content":"Soy un ingeniero de software con m√°s de 10 a√±os de experiencia en el sector. En todos estos a√±os he pasado por diversas empresas ejerciendo distintos roles y he podido desarrollarme profesionalmente en distintas √°reas.\nEste bagaje incluye el paso por grandes consultoras multinacionales, en las que he participado en diversos proyectos de distinta √≠ndole, he podido trabajar en proyectos en el extranjero integr√°ndome en diferentes culturas, coordinar peque√±os equipos de desarrollo, acompa√±ar en los inicios a perfiles junior, formar parte de proyectos con multitud de equipos y numerosos, etc.\nTambi√©n he tenido la ocasi√≥n de trabajar en una startup pr√°cticamente desde el momento de su creaci√≥n, lo cual me permiti√≥ experimentar lo dif√≠cil que es crear algo desde cero. Una experiencia muy valiosa que me permiti√≥ ver de cerca el otro lado de la moneda, el del empresario.\nMe apasiona la programaci√≥n y tengo muchas inquietudes que me hacen estar en un aprendizaje continuo. Esto es lo que me ha llevado a estudiar un m√°ster en Data Science \u0026amp; Big Data. Un √°rea apasionante, con mucho que decir en los pr√≥ximos a√±os y del cual me gustar√≠a formar parte en un futuro cercano.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"es","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://diegocastroviadero.com/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"Soy un ingeniero de software con m√°s de 10 a√±os de experiencia en el sector. En todos estos a√±os he pasado por diversas empresas ejerciendo distintos roles y he podido desarrollarme profesionalmente en distintas √°reas.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar c√≥mo he montado un cluster de Kubernetes utilizando Raspberry Pi y alg√∫n ejemplo de uso.\n \rParte I - Hardware Parte II - Sistema Operativo y Docker Parte III - (proximamente)  Sistema Operativo Una vez que todo el hardware est√° montado la siguiente decisi√≥n a tomar es qu√© sistema operativo instalar en las Raspberry. En el momento de tomar la decisi√≥n barajaba 3 opciones:\n Raspbian Hypriot Ubuntu  Raspbian es la distribuci√≥n oficial para raspberry, y ser√≠a una buena elecci√≥n. Sin embargo, no me he decantado por esta opci√≥n, y la raz√≥n principal es que en el momento de tomar la decisi√≥n no hab√≠a una versi√≥n final de 64 bits (estaba en beta).\nHypriot es una distribuci√≥n que desconoc√≠a totalmente y que viene con docker preinstalado, lo cual simplificar√≠a el proceso de instalaci√≥n y supondr√≠a un ahorro de tiempo. Tampoco me he decidido por esta opci√≥n, y el motivo es el mismo que con Raspbian, no existe una versi√≥n de 64 bits.\nTras haber descartado las dos distribuciones anteriores me entr√≥ la duda de si mi idea inicial de instalar una distribuci√≥n de 64 bits era una buena idea. Inicialmente pensaba que con una distribuci√≥n de 32 bits no podr√≠a aprovechar los 8 GB de RAM de las raspberry y de ah√≠ que buscase una distribuci√≥n de 64 bits. Tras investigar un poco, me di cuenta de que esto no era cierto del todo, con una distribuci√≥n de 32 bits s√≠ que se aprovechar√≠an los 8 GB de RAM. Un mismo proceso del sistema operativo podr√≠a usar como mucho 4 GB de RAM, pero entre varios procesos se podr√≠an consumir los 8 GB. A√∫n as√≠, mantuve mi idea inicial de instalar una distribuci√≥n de 64 bits, creo que no tiene sentido a d√≠a de hoy comenzar un proyecto optando por 32 bits, aunque esta elecci√≥n traiga ciertas \u0026ldquo;ventajas\u0026rdquo; inicialmente.\nFinalmente descubr√≠ que Ubuntu tiene distribuciones para ARM y que estas pueden ser de 64 bits. As√≠ que - \u0026ldquo;Se√±ores, ¬°Ya tenemos caballo ganador!\u0026rdquo;.\nCon el sistema operativo elegido lo siguiente era:\n flashear las 5 tarjetas de memoria actualizar y realizar ciertas configuraciones en las 5 raspberry instalar Docker en las 5 raspberry  En estos momentos me arrepent√≠ un poco de haber comprado 5 raspberry porque todo lo que fuese a hacer lo ten√≠a que repetir 5 veces. Si tienes claro el proceso, es cuesti√≥n de seguirlo a pies juntillas y repetirlo las veces que sea necesario. El problema viene cuando el proceso no est√° claramente definido, y con cada repetici√≥n se va refinando el mismo. Este \u0026ldquo;ir refinando el proceso a medida que lo vas repitiendo\u0026rdquo; no deber√≠a ser algo problem√°tico. El problema radica en mi persona y mi obsesi√≥n con algunas cosas, y en este caso mi obsesi√≥n no me permitir√≠a sentirme c√≥modo sabiendo que no he ejecutado el mismo proceso en todas las raspberry. Si cuando estoy en la √∫ltima raspberry me doy cuenta de que ser√≠a mejor hacer algo de forma diferente, me ver√≠a obligado a volver a hacerlo en todas las raspberry. Aqu√≠ es donde la situaci√≥n podr√≠a descontrolarse y llevarme much√≠simo m√°s tiempo del necesario con la √∫nica ventaja de tener todas las rapberry exactamente iguales.\nAntes de lanzarme a configurar las raspberry busqu√© la forma de automatizar todo el proceso de configuraci√≥n, lo cual me permitir√≠a dormir tranquilo sabiendo que todas las raspberry son almas gemelas sin tener que repetir manualmente el proceso de configuraci√≥n por en√©sima vez sobre la oveja negra del reba√±o. Y la b√∫squeda fue fruct√≠fera, me top√© con Cloud-Init y con Ansible.\nCloud-Init Cloud-Init es una tecnolog√≠a que permite inicializar una instancia y que viene de caja con Ubuntu. Cloud-Init detecta si es el primer arranque del sistema y si es el caso entra en acci√≥n permitiendo configurar: usuarios, claves ssh, particiones de disco, configuraci√≥n de red, etc. Cloud-Init puede obtener las acciones que tiene que ejecutar del propio disco de la instacia o podr√≠a obtenerlo a trav√©s de la red.\nEn mi caso, las acciones a actualizar las obtiene del propio disco: una vez flasheada la tarjeta SD copio un par de ficheros en la tarjeta con las configuraciones a realizar. Concretamente utilizo cloud-init para:\n actualizar los paquetes del sistema establecer el nombre de la instancia configurar el DNS desactivar la creaci√≥n del usuario por defecto del sistema operativo crear un usuario espec√≠fico establecer una clave SSH para el usuario deshabilitar el acceso al sistema con contrase√±a configuraci√≥n de una ip fija instalaci√≥n de paquetes adicionales: curl, vim, git y aptitude  Este es un ejemplo de fichero de configuraci√≥n de cloud-init de uno de los nodos del cluster:\n#cloud-config preserve_hostname: false hostname: rpicluster01 fqdn: rpicluster01.test package_update: true package_upgrade: true package_reboot_if_required: true manage_resolv_conf: true resolv_conf: nameservers: ['8.8.4.4', '8.8.8.8'] users: ## Disable creation of default user #- default ## Create user - name: rpicluster homedir: /home/rpicluster lock_passwd: true shell: /bin/bash # Generate key with command: ssh-keygen -t rsa -b 4096 -C \u0026quot;your_email@example.com\u0026quot; ssh_authorized_keys: - ************************************************************************************** sudo: - ALL=(ALL) NOPASSWD:ALL ## Disable password authentication with the SSH daemon ssh_pwauth: false ## Install additional packages on first boot packages: - curl - vim - git - aptitude final_message: \u0026quot;The system is finally up, after $UPTIME seconds\u0026quot;  La configuraci√≥n de red se establece en otro fichero diferente que tiene la siguiente pinta:\n# This file contains a netplan-compatible configuration which cloud-init # will apply on first-boot. Please refer to the cloud-init documentation and # the netplan reference for full details: # # https://cloudinit.readthedocs.io/ # https://netplan.io/reference # # Some additional examples are commented out below version: 2 ethernets: eth0: dhcp4: false addresses: [192.168.86.51/24] gateway4: 192.168.86.1 mtu: 1500 nameservers: addresses: [8.8.4.4, 8.8.8.8] optional: true #wifis: # wlan0: # dhcp4: true # optional: true # access-points: # myhomewifi: # password: \u0026quot;S3kr1t\u0026quot; # myworkwifi: # password: \u0026quot;correct battery horse staple\u0026quot; # workssid: # auth: # key-management: eap # method: peap # identity: \u0026quot;me@example.com\u0026quot; # password: \u0026quot;passw0rd\u0026quot; # ca-certificate: /etc/my_ca.pem  Para flashear la imagen del sistema operativo en la tarjeta SD utilizo rpiimager. Esta herramienta te provee de una interfaz gr√°fica muy sencilla en la que en primer lugar se selecciona la imagen que quieres flashear, en segundo lugar se elige d√≥nde la quieres flashear y por √∫ltimo se inicia la grabaci√≥n. Esta herramienta te evita tener que descargar la imagen del sistema operativo ya que es la propia herramienta quien se encarga de descargarla.\nAl arrancar la raspberry por primera vez cloud-init se activar√° y ejecutar√° las acciones anteriores, lo √∫nico que hay que hacer es esperar unos minutos. Alguien perspicaz, se habr√° dado cuenta que hay dos acciones en la lista anterior que no son iguales para todas las raspberry del cluster: establecer el nombre de la instancia y configurar una ip fija. Esto hace que haya que tener para cada instancia del cluster un fichero de configuraci√≥n diferente. Y en este punto es donde entra en acci√≥n Ansible.\nAnsible Ansible, resumi√©ndolo mucho, es una herramienta de automatizaci√≥n de tareas. Dado un fichero de inventario, en el que se definen una serie de m√°quinas; y un fichero de tareas (playbook), en el que se definen una serie de tareas; Ansible se encargar√° de ejecutar cada una de las tareas en cada una de las m√°quinas. Con el a√±adido de que la ejecuci√≥n de dichas tareas es idempotente, es decir, que si alguna de las tareas ya se ha ejecutado en alguna de dichas m√°quinas, no la volver√° a ejecutar. Esto es una simplificaci√≥n muy grande de todo el universo de Ansible, pero en este post no quiero entrar en detalles sobre Ansible, sino en explicar lo m√≠nimo para que se entienda de qu√© forma se ha utilizado esta herramienta para montar el cluster.\nComo he mencionado anteriormente, he utilizado Ansible para la generaci√≥n de los ficheros de configuraci√≥n de cloud-init. Y este es un caso de uso un poco especial, puesto que no se ajusta a la descripci√≥n anterior sobre el funcionamiento b√°sico de Ansible. S√≠ que disponemos de un fichero de inventario, pero no utilizamos Ansible para ejecutar ninguna tarea sobre las m√°quinas del inventario, sino para obtener unos datos sobre dichas m√°quinas y utilizarlos para generar unos ficheros de configuraci√≥n en el puesto local.\nEste es un extracto del fichero de inventario:\n[rpicluster01] 192.168.86.51 [rpicluster01:vars] custom_hostname=rpicluster01 [rpicluster02] 192.168.86.52 [rpicluster02:vars] custom_hostname=rpicluster02 [rpicluster03] 192.168.86.53 [rpicluster03:vars] custom_hostname=rpicluster03 [rpicluster04] 192.168.86.54 [rpicluster04:vars] custom_hostname=rpicluster04 [rpicluster05] 192.168.86.55 [rpicluster05:vars] custom_hostname=rpicluster05 [rpicluster:children] rpicluster01 rpicluster02 rpicluster03 rpicluster04 rpicluster05  En este caso hemos definido el inventario en un fichero en formato INI. Se puede ver que se han definido varios grupos. Hay un grupo con un solo elemento para cada una de las m√°quinas del cluster y as√≠ poder hacer referencia a una m√°quina concreta:\n rpicluster01 rpicluster02 rpicluster03 rpicluster04 rpicluster05  Tambi√©n hay un grupo que est√° compuesto por todas las m√°quinas del cluster, para poder hacer referencia a todo el cluster:\n rpicluster  Para cada una de las m√°quinas se define una propiedad custom_hostname que contiene el nombre de la m√°quina.\n(se puede ver el fichero completo aqu√≠)\nA continuaci√≥n se muestra el playbook de ansible que genera los ficheros de configuraci√≥n de cloud-init para las m√°quinas del cluster:\n--- - hosts: rpicluster gather_facts: false tasks: - name: create directories file: path: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}\u0026quot; state: directory delegate_to: localhost - name: generate user-data config file from template template: src: template_userdata.j2 dest: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}/user-data\u0026quot; delegate_to: localhost - name: generate network-config file from template template: src: template_networkconfig.j2 dest: \u0026quot;../../cloud-init/{{ hostvars[inventory_hostname]['custom_hostname'] }}/network-config\u0026quot; delegate_to: localhost  Se definen 3 tareas:\n La tarea 1 se encarga de crear un directorio para cada una de las m√°quinas del inventario La tarea 2 genera el fichero de configuraci√≥n user-data a partir de un template La tarea 3 genera el fichero de configuraci√≥n network-config a partir de un template  (se puede ver el playbook completo aqu√≠)\nDocker Gracias a Ansible, la instalaci√≥n de Docker en todas las m√°quinas se ha simplificado al m√°ximo. He encontrado un playbook, que he utilizado casi tal cual, que se encarga de instalar Docker en sistemas debian. Se puede encontrar la versi√≥n que he utilizado aqu√≠.\nConclusi√≥n Como conclusi√≥n he de decir que tanto cloud-init como Ansible han sido dos grandes descubrimientos. Sobre todo Ansible, ya que veo que es una herramienta que puedo empezar a utilizar en mi d√≠a a d√≠a a nivel profesional.\nLa √∫nica pega que le veo a Ansible, es que algunos aspectos no son compatibles con Windows. Actualmente utilizo un Windows 10 y he podido hacer uso de Ansible sin grandes complicaciones a trav√©s de WLS. El √∫nico inconveniente que me he topado hasta el momento, ha sido a la hora de utilizar Ansible Vault, ya que para ciertas situaciones es necesario modificar los permisos de algunos ficheros, lo cual no es posible en WLS a d√≠a de hoy (o al menos yo no he encontrado la manera de hacerlo).\n","date":1601205540,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1602257160,"objectID":"5aa94f4c61de593b99b1deac7a6b87ae","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-ii/","publishdate":"2020-09-27T11:19:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-ii/","section":"post","summary":"En esta serie de posts explicar√© c√≥mo he montado un cluster de Kubernetes con Raspberry Pi. En esta segunda parte explico qu√© sistema operativo he decidido instalar en los nodos del cluster y c√≥mo instalar Docker en los mismos.","tags":["cluster","raspberry","docker","ubuntu","ansible","cloud-init"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte II)","type":"post"},{"authors":null,"categories":null,"content":"Esta es una serie de posts en la que voy a explicar c√≥mo he montado un cluster de Kubernetes utilizando Raspberry Pi y alg√∫n ejemplo de uso.\n Parte I - Hardware \rParte II - Sistema Operativo y Docker Parte III - (proximamente)  Introducci√≥n Kubernetes es una tecnolog√≠a de orquestaci√≥n de contenedores que lleva en el mercado ya varios a√±os. Sin embargo, hasta la fecha, no he tenido la oportunidad de \u0026ldquo;jugar\u0026rdquo; con ella. Llevo varios a√±os trabajando intensamente con Docker, y ten√≠a como asignatura pendiente empezar a utilizar alg√∫n orquestador de contenedores. Como a nivel profesional no he tenido la ocasi√≥n de hacerlo, y como pienso que como mejor se aprende es practicando, nada mejor para aprender Kubernetes, que montarme un cluster Kubernetes desde cero. Quiz√°s llegue un poco tarde, pero creo que es mejor tarde que nunca.\nFinalmente me he decidido por montar un cluster on premise en mi casa. Al principio pens√© que lo m√°s sencillo, r√°pido y barato ser√≠a hacerlo en el cloud, pero lo cierto es que me daba mucha pereza. Demasiados proveedores, cada uno con unos servicios gratuitos, con unas condiciones de pago por uso diferentes, en alguno de los cuales ya hab√≠a consumido dicho uso gratuito, etc.\nAunque montar un cluster on premise suponga un desembolso inicial superior y un mayor esfuerzo, frente a montarlo en el cloud, encuentro al menos dos motivos que han hecho que me decline por esta opci√≥n.\nEn primer lugar, considero que montando el cluster on premise me puede simplificar el aprendizaje de los conceptos b√°sicos, ya que no me ver√© distra√≠do por la terminolog√≠a y servicios accesorios varios ofrecidos por los proveedores cloud.\nEn segundo lugar, me da mucha tranquilidad saber que si lo apago no consumo nada. S√© que este argumento puede no tener mucho sentido, ya que en el cloud, uno tiene control sobre los servicios que contrata y tambi√©n podr√≠a \u0026ldquo;apagarlo\u0026rdquo; en cualquier momento. La cosa es que el mundo de los proveedores cloud tambi√©n es nuevo para m√≠, y el sistema de facturaci√≥n me parece un poco complejo. Ser√≠a otra cosa desconocida adicional a la que enfrentarme. Mi objetivo inicial es aprender Kubernetes, no es conocer como montar un cluster kubernetes en Amazon, Google o Azure y cu√°nto me van a cobrar por ello. En el pasado ya he tenido alg√∫n susto con grandes facturas de proveedores cloud, por creer que estaba haciendo uso de los servicios gratuitos, cuando no era cierto.\nComponentes El cluster est√° compuesto inicialmente de 5 Raspberry Pi modelo 4b con 8GB de RAM. Esto hace que el cluster disponga de:\n 20 cores a 1'5 GHz 40 GB de memoia RAM  Cada Raspberry tiene una tarjeta de memoria microSD Samsung EVO Plus de 32GB. Este almacenamiento ser√° √∫nicamente para la ejecuci√≥n del sistema operativo. Inicialmente tambi√©n lo utilizar√© para la persistencia de los contenedores del cluster. M√°s adelante cuando me adentre en el mundo de los vol√∫menes persistentes, montar√© un mecanismo de persistencia dedicado.\nCon el objetivo de facilizar el montaje del cluster y reducir el n√∫mero de clables necesarios, he comprado unos m√≥dulos HAT PoE que me permiten alimentar las Raspberry por PoE. De esta forma puedo prescindir de los transformadores y los cables USB para alimentar las Raspberry, ya que con el mismo cable ethernet alimento las Raspberry y les proporciono conexi√≥n de red.\nPara poder alimentar las Raspberry por PoE he comprado un switch Netgear GS108PP con 8 puertos y con alimentaci√≥n PoE en todos. Esto me permite tener hasta 7 Raspberry alimentadas y conectadas, ya que uno de los puertos lo utilizo para conectar el switch a la red.\nPara albergar todos los componentes he comprado un armario rack de 19\u0026rdquo; Phasak PHP 2106. El armario tiene 6U de espacio en total que ser√° utilizado de la siguiente forma:\n 1U para una reglega de 8 tomas con interruptor 1U para el switch que va sobre una bandeja 2U para alojar hasta 12 Raspberry Pi 2U libres  Para colocar todas las Raspberry en fila en el armario rack, he imprimido este proyecto, disponible en Thingiverse. Ocupando 2U del rack se pueden tener 12 Raspberry. Cada Raspberry est√° en una bandeja extra√≠ble, haciendo muy sencillo una sustituci√≥n. La mayor√≠a de ejemplos que hab√≠a visto para apilar Raspberry, lo hacian de tal forma que el recambio de una de ellas implicar√≠a desmontar todo. Este es uno de los pocos que he encontrado que facilita el mantenimiento.\nAntes de poner el cluster en funcionamiento de forma continuada me gustar√≠a tener un mecanismo para medir el consumo del mismo. Tengo pendiente comprar alg√∫n dispositivo que me permita medir el consumo y tener alg√∫n tipo de hist√≥rico para calcular su coste. He hecho una b√∫squeda r√°pida y he visto un mont√≥n de enchufes baratos que miden el consumo, aunque ninguno me ha convencido. Me gustar√≠a tener una soluci√≥n que se integre con Home Assistant, que es la soluci√≥n que tengo en casa para la dom√≥tica. Este aspecto queda fuera del √°mbito de este post y no me extender√© m√°s en ello.\nConclusi√≥n La combinaci√≥n de estos componentes me permite tener un cluster:\nCompacto El armario rack de 19\u0026rdquo; y 6U es un armario de reducidas dimensiones que puedo colocar en cualquier sitio de la casa.\nVentilado El armario rack dispone de 2 grandes ventiladores en la parte superior. Adem√°s cada Raspberry dispone de un ventilador ya que el HAT PoE incluye uno. Creo que es ventilaci√≥n suficiente para dejar el cluster encendido de continuo sin miedo a que se sobrecaliente.\nOrdenado Los HAT PoE han ayudado mucho a que el armario no tenga demasiados cables en su interior y a que la regleta tenga m√°s tomas disponibles para su uso.\nIluminado El armario rack dispone tambi√©n de iluminaci√≥n led, esto me da libertad para poder situar el armario rack en cualquier punto de la casa y poder hacer un mantenimiento del mismo sin problemas de falta de luz.\nExtensible Gracias al proyecto de thingiverse puedo colocar hasta 12 Rasperry ocupando 2U del armario. Con las 2U que me quedan libres podr√≠a:\n Colocar otras 12 raspberry pi Colocar alg√∫n dispositivo SAI Dedicarlo a almacenamiento etc  BOM  5x Raspberry Pi modelo 4b con 8GB de RAM 5x Samsung EVO Plus de 32GB 5x HAT PoE 1x Netgear GS108PP 1x Phasak PHP 2106 1x Reglega de 8 tomas con interruptor 1x Bandeja 1x Cables de red de 25cm 1x Tornillos y tuercas para armario rack 1x Tornillos M2.5 para Raspberry Pi 2x Varilla roscada M4 de 1m (comprado en ferreter√≠a) 8x Tuercas M4 (comprado en ferreter√≠a)  ","date":1600443060,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1601197920,"objectID":"ea7e4207f32ed47280f9cd6d665567af","permalink":"https://diegocastroviadero.com/post/monto-un-cluster-kubernetes-con-rpi-parte-i/","publishdate":"2020-09-18T15:31:00Z","relpermalink":"/post/monto-un-cluster-kubernetes-con-rpi-parte-i/","section":"post","summary":"En esta serie de posts explicar√© c√≥mo he montado un cluster de Kubernetes con Raspberry Pi. En esta primera parte explico c√≥mo est√° configurado el cluster en cuanto a hardware se refiere.","tags":["cluster","raspberry"],"title":"Monto un cluster Kubernetes con Raspberry Pi (parte I)","type":"post"},{"authors":[],"categories":[],"content":"Sistema de automatizaci√≥n de fichajes  Objetivo El principal objetivo es simplificar el proceso de fichajes de una empresa\nUn objetivo secundario es el de utilizar tecnolog√≠as para seguir creciendo como profesional de la Inform√°tica.\n ## Contexto - Recordar cada una de las acciones a realizar - Para ciertas acciones hay que escribir un texto adicional - Login requerido para realizar cada una de las acciones - Intranet no adaptada al uso desde el m√≥vil    ## Requisitos - Fichaje lo m√°s fiel posible a la realidad - El usuario no tiene que recordar realizar ninguna acci√≥n - Las acciones manuales por parte del usuario ser√°n muy sencillas - Se tendr√°n en cuenta los fichajes realizados directamente en la intranet    Soluci√≥n La soluci√≥n desarrollada es un chatbot de telegram:\nTimeHammerBot\nhttps://t.me/TimeHammerBot\nLo √∫nico necesario para poder utilizarla ser√° disponer de un smartphone y tener instalada la aplicaci√≥n de mensajer√≠a Telegram. Tambi√©n compatible con la versi√≥n web de Telegram\n ## Funcionamiento #### Trabajador 1. Registro en el chatbot - Hora de inicio y final de la jornada - Hora de inicio y final de la comida - Lugar de trabajo 1. Se olvida de volver a fichar    ## Funcionamiento #### Chatbot 1. Llegada la hora de una determinada acci√≥n - Comprueba el estado del trabajador - Si procede, notifica al trabajador 1. El trabajador recibe la notificaci√≥n - Confirma/Postpone/Cancela la acci√≥n 2. El chatbot recibe la respuesta - Ejecuta la acci√≥n en la intranet - Se queda a la espera - Ignora la acci√≥n hasta el d√≠a siguiente    ## Ejemplo 1 Trabajador  lunes | comienzo jornada | 8:00 - A las 8:00 recibir√° un mensaje pregunt√°ndole si ya ha comenzado a trabajar - Debajo del mensaje aparecer√°n una serie de botones: S√≠, +5m, +10m, +15m, +20m, No - Con solo pulsar un bot√≥n el chatbot actuar√° en consecuencia    ## Ejemplo 2 Trabajador  vienes | comienzo jornada | 8:00 - Comienza a trabajar antes de lo normal - Fichaje manual en la intranet a las 7:30 - A las 8:00 el chatbot comprobar√° el estado y ver√° que no tiene nada que notificar    Extra I El chatbot busca molestar lo menos posible\n Fines de semana Festivos  Ciudad de trabajo   Vacaciones   Extra II No se persiste la contrase√±a de los usuarios, se guardan en memoria.\nSi se reinicia el contenedor que tiene en memoria las contrase√±as, se enviar√° un mensaje a los trabajadores para que vuelvan a introducir su contrase√±a.\n DEMO  ## Objetivos cumplidos - Todos los fichajes requieren de una confirmaci√≥n y son fieles a la realidad - El usuario ya no tiene que recordar realizar una determinada acci√≥n - La √∫nica acci√≥n manual del usuario consiste en pulsar un bot√≥n- El usuario ya no tiene que conectarse a una intranet - Al recuperar siempre el estado del usuario de la intranet, se posibilita combinar el uso de ambos sistemas para situaciones excepcionales    Stack tecnol√≥gico  Java Quarkus Docker Telegram Bots Kafka PostgreSQL   Event Driven Architecture I  Event Driven Architecture II  Roadmap I Reducci√≥n de llamadas a Comunytek En la versi√≥n actual se realizan:\n30 * 12 + 6 * 12 + 4 = 436 llamadas/usuario/d√≠a\nCon la versi√≥n mejorada se realizar√≠an:\n3 llamadas/acci√≥n * 4 acciones/d√≠a/usuario = 12 llamadas/usuario/d√≠a\n Roadmap II Kubernetes I  Roadmap II Kubernetes II  Roadmap II Kubernetes III  Roadmap III  Anular el registro Modificar la configuraci√≥n Mejorar validaciones en el registro A√±adir tests Tunear configuraci√≥n Kafka A√±adir monitorizaci√≥n de m√≥dulos NLP Modulo de administraci√≥n   ## Chatbots I - Los chatbots son una herramienta mucho potencial que permite aplicar un nuevo enfoque para resolver ciertos problemas - Los usuarios est√°n cada vez m√°s acostumbrados a las aplicaciones de mensajer√≠a - Tienen peor fama de la que se merecen porque muchos de los que se hacen llamar chatbots, hacen un mal (o nulo) procesamiento del lenguaje natural y realmente se trata de una sucesi√≥n de condiciones l√≥gicas que ejecutan ciertas acciones    ## Chatbots II - Con este proyecto se muestra un **enfoque diferente** de chatbot, basado en el uso de **comandos**. Que mediante el uso de diferentes **teclados** que se **adaptan** al tipo de respuesta que esperas del usuario, **mejora** mucho la **usabilidad**    Caso de Uso Nuevo canal de comunicaci√≥n para la realizaci√≥n de guardias\n","date":1597384200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599290520,"objectID":"0fce65b41a51745a77269db256dfe812","permalink":"https://diegocastroviadero.com/slides/timehammer/","publishdate":"2020-08-14T05:50:00Z","relpermalink":"/slides/timehammer/","section":"slides","summary":"Sistema de automatizaci√≥n de fichajes","tags":[],"title":"TimeHammer","type":"slides"},{"authors":null,"categories":null,"content":"Este es un proyecto personal en el que llevo trabajando desde comienzos del 2020, poco antes del confinamiento por la COVID-19. Consiste en un sistema que permite recordar y simplificar la realizaci√≥n de los fichajes en una empresa.\nSe trata de TimeHammerBot un chatbot de Telegram en el cual el trabajador se registra indicando su lugar y horario habitual de trabajo. Una vez registrado, el chatbot se encargar√° de recordarle los momentos en los que se debe realizar un fichaje. No s√≥lo se trata de recordatorios en los diferentes momentos de fichaje, sino que el chatbot propone una serie de botones integrados en los mensajes de recordatorio, que al ser pulsados ejecutan la acci√≥n de fichar.\nSe ha desarrollado una arquitectura orientada a eventos EDA. El proyecto se ha dividido en diversos m√≥dulos, cada uno con una responsabilidad, que se comunican entre si mediante el env√≠o de mensajes. Estos mensajes representan los diferentes eventos que desencadenan la l√≥gica de negocio.\nPara el desarrollo se ha utilizado Quarkus, que es un stack basado en java que posibilita la compilaci√≥n a c√≥digo nativo. Quarkus permite tanto la programaci√≥n imperativa como la reactiva. En este proyecto se ha optado por la programaci√≥n reactiva.\nPara el env√≠o de los mensajes se ha utilizado Kafka puesto que la integraci√≥n con Quarkus es muy sencilla.\nPara la ejecuci√≥n en producci√≥n se utiliza Docker. Cada uno de los m√≥dulos que componen el proyecto tiene una imagen de Docker asociada. En el entorno de producci√≥n se ejecutan contenedores de dichas im√°genes. Actualmente son se utiliza ning√∫n orquestador de contenedores, directamente se est√°n arrancando con docker-compose. El siguiente paso planificado es la utilizaci√≥n de kubernetes como orquestador de contenedores.\n","date":1597294800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599290280,"objectID":"915e32669415332108040900e6a5c2dc","permalink":"https://diegocastroviadero.com/project/timehammer/","publishdate":"2020-08-13T05:00:00Z","relpermalink":"/project/timehammer/","section":"project","summary":"Sistema de automatizaci√≥n de fichajes","tags":["Java","Quarkus","EDA","Kafka","Docker"],"title":"TimeHammer","type":"project"},{"authors":null,"categories":null,"content":"Contexto En el a√±o 2019 hubo un cambio de ley que obliga a todas las empresas de Espa√±a a proporcionar informaci√≥n sobre la jornada laboral de sus trabajadores, lo que comunmente conocemos como fichajes.\nMi empresa se ha adaptado al cambio de legislaci√≥n a√±adiendo una nueva secci√≥n en la intranet para que cada empleado pueda registrar la jornada laboral. El enfoque que ha seguido mi empresa es el fichaje \u0026ldquo;en tiempo real\u0026rdquo;, es decir, se toma el momento en el que se est√°n registrando las acciones como el momento en el que las realizas. Esto obliga a fichar en el momento real en el que empiezas a trabajar, en el que comienzas a comer, en el que terminas de comer\u0026hellip; No existe ninguna posibilidad de correcci√≥n por parte de los trabajadores, si se olvida registrar alguna de las acciones hay que escribir un email al responsable para indicarlo.\nEste enfoque de \u0026ldquo;tiempo real\u0026rdquo; no es el √∫nico posible, he visto otras empresas que tambi√©n proporcionan un apartado en su intranet, pero que permiten hacer el fichaje \u0026ldquo;en diferido\u0026rdquo;.\nCuestiones a parte ser√≠an si estas implementaciones cumplen con la ley o qu√© responsabilidades tiene el trabajador o qu√© pasar√≠a si se hace una inspecci√≥n y los fichajes del trabajador no son correctos.\nProblema La soluci√≥n tomada por mi empresa no es una soluci√≥n pensada para el trabajador que sea c√≥moda de usar, todo lo contrario:\n El trabajador tiene que recordar todas las acciones que tiene que realizar Para ciertas acciones el trabajador tiene no s√≥lo que realizar la acci√≥n, sino que tiene que escribir un texto v√°lido para dicha acci√≥n Para realizar cada una de las acciones el trabajador tiene que acceder a la intranet, teniendo que introducir sus credenciales Algunas de las acciones se realizan desde sitios donde no hay un ordenador, por lo que hay que acceder a la intranet desde el m√≥vil cuando la intranet no est√° adaptada para ello. Los men√∫s son muy peque√±os y es dif√≠cil llegar a la zona de fichajes  Objetivo Me he propuesto simplificar todo este proceso de tal forma que los fichajes se realicen de una manera sencilla, y lo m√°s fieles posible a la realidad. Adem√°s utilizar√© tecnolog√≠as que me permitan seguir desarroll√°ndome como profesional de la Inform√°tica.\nRequisitos Estos son los requisitos funcionales que guiar√°n el planteamiento y desarrollo de la soluci√≥n:\n Fichaje lo m√°s fiel posible a la realidad Las acciones manuales por parte del usuario ser√°n muy sencillas Se tendr√°n en cuenta los fichajes realizados directamente en la intranet  Soluci√≥n La soluci√≥n desarrollada es un chatbot de telegram: TimeHammerBot. Lo √∫nico necesario para podeer utilizarla ser√° disponer de un smartphone y tener instalada la aplicaci√≥n de mensajer√≠a Telegram.\nFuncionamiento El trabajador se registrar√° en el chatbot TimeHammerBot de Telegram. Para ello tendr√° que indicar la empresa en la que trabaja, los credenciales para acceder a la intranet donde se realiza el fichaje manual y los horarios habituales: hora de comienzo y fin de la jornada laboral y hora de comienzo y fin de la comida (para cada d√≠a de la semana). Una vez realizado el registro podr√° olvidarse de volver a acceder a la intranet para realizar un fichaje. A partir de ese momento ser√° el chatbot quien le recuerde a las horas configuradas, la realizaci√≥n de las acciones pertinentes. Adem√°s junto con cada recordatorio, se proporcionar√°n una serie de botones que permitir√°n confirmar la realizaci√≥n de dichas acciones.\nPor ejemplo, si el trabajador ha indicado que los lunes suele comenzar la jornada laboral a las 8:00, a esa hora recibir√° un mensaje en Telegram pregunt√°ndole si ya ha comenzado a trabajar. Debajo del mensaje aparecer√°n una serie de botones: \u0026ldquo;S√≠\u0026rdquo;, \u0026ldquo;+5m\u0026rdquo;, \u0026ldquo;+10m\u0026rdquo;, \u0026ldquo;+15m\u0026rdquo;, \u0026ldquo;+20m\u0026rdquo;, \u0026ldquo;No\u0026rdquo;. Al pulsar el bot√≥n \u0026ldquo;S√≠\u0026rdquo;, el chatbot se encargar√° de registrar el inicio de la jornada en la intranet. Al pulsar los botones \u0026ldquo;+Xm\u0026rdquo;, se le pedir√° al chatbot que se espere X minutos antes de volver a preguntar. Al pulsar el bot√≥n \u0026ldquo;No\u0026rdquo;, se le indicar√° al chatbot que ese d√≠a no se trabaja y hasta el d√≠a siguiente no volver√° a preguntar nada.\nEl chatbot recuperar√° de la intranet las vacaciones del trabajador con el objetivo de no molestar durante ese periodo de tiempo. Tambi√©n tendr√° en cuenta los d√≠as festivos de la ciudad de trabajo del trabajador (motivo por el cual durante el registro hay que indicar la ciudad de trabajo).\nEl chatbot es un mero intermediario, no guardar√° en ning√∫n momento los fichajes del trabajador. Para conocer el estado de un trabajador lo recuperar√° de la intranet de la empresa del trabajador. De esta forma se puede combinar el uso del chatbot junto con la realizaci√≥n de ciertas acciones de forma manual. Por ejemplo, si el trabajador ha indicado que los viernes suele comenzar a trabajar a las 8:00, pero excepcionalmente, un viernes comienza su jornada a las 7:30, podr√° acceder a la intranet y registrar su fichaje a las 7:30. Cuando sean las 8:00 el chatbot tendr√° en cuenta las posibles acciones realizadas manualmente en la intranet antes de preguntar nada. Por lo que en este caso, a las 8:00 el chatbot no preguntar√° nada al trabajador.\nCon este modelo de funcionamiento se cumplen los 3 requisitos planteados para el proyecto:\n Todos los fichajes requerir√°n de una confirmaci√≥n por parte del usuario y ser√°n fieles a la realidad. El usuario se olvida de tener que conectarse a una intranet y registrar una serie de acciones y en su lugar lo √∫nico que tiene que hacer es pulsar un bot√≥n cuando le llega un mensaje al Telegram. Al no guardar el estado de los trabajadores y recuperarlo siempre de la intranet, se posibilita combinar el uso de ambos sistemas.  Detalles Para conocer m√°s detalles sobre el proyecto puedes acceder aqu√≠\nConclusi√≥n Este proyecto ha supuesto un reto bastante interesante por diversos motivos:\n- Llevar un proyecto adelante de principio a fin\n El camino que hay que seguir desde que se tiene una idea hasta que esta se materializa siempre es complicado. A lo largo de este camino existen diversos momentos, en los que lo m√°s f√°cil es no complicarse y ceder en el intento. Llegar a desplegar en producci√≥n una primera versi√≥n estable y funcional es motivo suficiente para sentirse orgulloso.\n - Afrontar un nuevo paradigma de programaci√≥n\n Cambiar la manera de pensar no es trivial. Tareas que considerabas sencillas, de repente, se convierten en complicados rompecabezas. Ante la m√°s m√≠nima complicaci√≥n es tentador volver a las antiguas costumbres para salir del paso y seguir avanzando. Ha resultado agotador ser fiel a programaci√≥n reactiva.\n - Nuevas tecnolog√≠as\n En este proyecto he utilizado muchas tecnolog√≠as desconocidas para mi: Quarkus, Kafka, EDA, compilaci√≥n nativa de java, im√°genes distroless. Para mi siempre es motivador enfrentarme a un nuevo framework, lenguaje, herramienta\u0026hellip; me recuerda a cuando era ni√±o y me regalaban un juguete. Lo que resulta un verdadero reto es realizar un proyecto en el que la gran mayor√≠as de las tecnolog√≠as son desconocidas y pasas m√°s tiempo en las p√°ginas de documentaci√≥n que programando.\n - Ponerse un objetivo y ce√±irse a √©l\n Cuando no tienes a un jefe que te va guiando hacia una meta es complicado no desviarse del camino y resulta muy sencillo irse por las ramas. M√°s a√∫n cuando tienes un mont√≥n de \u0026ldquo;juguetitos\u0026rdquo; nuevos que probar e investigar. Este proyecto no ha sido una excepci√≥n, de hecho, la soluci√≥n final es la tercera que se ha desarrollado desde cero. El proyecto comenz√≥ siendo serverless, bas√°ndose en el uso de Firebase. Despu√©s se descart√≥ la idea de serverless y pas√≥ a ser un monolito desarrollado en Quarkus. Finalmente se ha mantenido el uso de Quarkus, pero se ha modularizado implementando una arquitectura orientada a eventos.\n Se trata de una primera versi√≥n funcional con mucho margen de mejora. He incorporado una gran cantidad de novedades tecnol√≥gicas, dada mi experiencia,y hasta el momento no he podido profundizar mucho en ellas para poder tener esta primera versi√≥n funcional lo antes posible.\n","date":1580494860,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1599288360,"objectID":"f0341a7a0828ccbec3bc1dd1ee582041","permalink":"https://diegocastroviadero.com/post/como-automatizar-los-fichajes-de-mi-empresa/","publishdate":"2020-01-31T18:21:00Z","relpermalink":"/post/como-automatizar-los-fichajes-de-mi-empresa/","section":"post","summary":"En este post explicar√© el proyecto que he desarrollado para automatizar los fichajes de mi empresa","tags":["timehammer","chatbot","telegram"],"title":"C√≥mo he automatizado los fichajes de mi empresa","type":"post"},{"authors":null,"categories":null,"content":"Llevo ya unos meses pensando en renovar los equipos que tengo, bien porque se han quedado desfasados o bien porque quiero ampliar sus funcionalidades y se quedan cortos de recursos. Actualmente dispongo de los siguientes equipos:\n port√°til de 13\u0026rsquo; con windows (ligero) port√°til de 15\u0026rsquo; con windows (antiguo) port√°til de 17\u0026rsquo; con windows (el m√°s potente) raspberry pi con raspbian para la dom√≥tica raspberry pi con raspbian para la gesti√≥n de finanzas iMac NAS con 2 discos de 2TB en RAID0  El NAS cumple con m√∫ltiples funciones:\n almacenamiento de documentos almacenamiento de backups centro multimedia centro de descargas  Para el almacenamiento de documentos utilizo software propio de QNAP que me permite tener sincronizados determinados directorios de un equipo con el NAS. Adem√°s tengo la posibilidad de acceder a los mismos, tambi√©n a trav√©s de aplicaciones de QNAP, desde los dispositivos m√≥viles.\nPara la realizaci√≥n de los backups utilizo software propio de QNAP para los equipos Windows, que me permite programar backups de forma peri√≥dica. En el caso del iMac, utilizo TimeMachine que lo hace de forma autom√°tica y transparente.\nQuien realmente cumple con la funci√≥n de centro multimedia es Plex Media Server, que est√° instalado en el NAS, y es quien me permite visualizar el contenido multimedia a trav√©s de la Smart TV y de los dispositivos m√≥viles.\nPara la realizaci√≥n de descargas utilizo un cliente BitTorrent instalado en el NAS, que me permite controlarlo desde los dispositivos m√≥viles.\nLo que me gustar√≠a es retirar algunos de los port√°tiles que tengo junto con el iMac y en su lugar comprarme un buen PC que sea potente y que me permita realizar proyectos personales de Data Science.\nMotivaci√≥n Una renovaci√≥n del hardware no tendr√≠a por qu√© llevarme a un replanteamiento de la organizaci√≥n en lo que respecta al almacenamiento. Sin embargo, existen una serie de inconvenientes/mejoras pendientes que llevo arrastrando desde hace un tiempo y que son los verdaderos motivadores del cambio:\n En el iMac tengo configurado el TimeMachine para hacer los backups contra el NAS. Parece que no funciona muy bien, porque desde que lo configur√© sale un aviso en el NAS indicando que hay datos err√≥neos en alguno de los vol√∫menes. Adem√°s, el iMac apenas lo utilizo y es uno de los equipos que quiero jubilar S√≥lamente uno de los port√°tiles con Windows tiene configurados los backups y la sincronizaci√≥n de documentos Las Raspberry PI no tienen configurado ning√∫n tipo de backup contra el NAS y, tras haber investigado, QNAP no ofrece demasiadas opciones para Linux Me gustar√≠a tener una √∫nica soluci√≥n tanto de backups como de sincronizaci√≥n de documentos, para todos los sistemas operativos El QNAP funciona muy lento, las opciones de ampliaci√≥n de sus recursos hardware son muy limitadas y adem√°s quiero ampliar sus funcionalidades (ej: a√±adirle un repositorio de c√≥digo, poder hacer seguimiento de series y pel√≠culas con couchpotato o alternativas similares, etc.)  As√≠ que aprovechando que voy a hacer cambios en el hardware y teniendo en cuenta todos los puntos anteriores he decidido hacer un cambio radical.\nQu√© me gustar√≠a tener Me gustar√≠a tener lo siguiente:\n Tener backups de las Raspberry PI de forma peri√≥dica y autom√°tica Tener sincronizados con el NAS algunos directorios tanto de equipos Windows como Linux Tener las fotos/videos realizadas con dispositivos m√≥viles guardadas directamente en el NAS de forma autom√°tica Tener forma de visualizar a trav√©s del m√≥vil las fotograf√≠as del NAS Tener forma de visualizar a trav√©s del m√≥vil los documentos del NAS Poder montar un volumen del NAS en cualquiera de los port√°tiles o PC para hacer un backup manual inicial de documentos o fotos Que el NAS haga de forma peri√≥dica un backup encriptado a alg√∫n cloud Disponer de un cliente de descargas de BitTorrent y poder controlarlo a trav√©s del m√≥vil Utilizar Plex Media Server como media center A√±adir Radarr, Sonarr y Jackett (o CouchPotato) para el seguimiento de series y pel√≠culas y descargas automatizadas Tener un repositorio de c√≥digo git Poder editar documentos, hojas de c√°lculo, presentaciones, diagramas directamente a trav√©s del NAS Aplicaci√≥n de mensajer√≠a privada Aplicaci√≥n de notas privada Aplicaci√≥n de calendario privada Poder ampliar libremente los recursos del NAS en un futuro Poder ampliar libremente la funcionalidad del NAS  Alternativas La primera disyuntiva a la que me enfrento es si comprar otro NAS ya montado (al estilo del QNAP) o mont√°rmelo yo mismo. La ventaja de comprar uno ya montado es que es \u0026ldquo;enchufar y listo\u0026rdquo;, con el inconveniente de que este tipo de NAS no son demasiado flexibles. La venjata de montarse un NAS es que son totalmente customizables y extensibles, la pega es que requieren de mucho tiempo de investigaci√≥n, selecci√≥n de componentes, montaje, configuraci√≥n y selecci√≥n de software.\nNAS ya montado He descubierto que Synology tiene mejor integraci√≥n con linux. He encontrado dos modelos que se ajustan a los requisitos: DS918+ y DS1618+.\nDS918+ Cumple con casi todos los requisitos, la √∫nica excepci√≥n es la ampliaci√≥n de recursos. Tiene 4 bah√≠as y la posibilidad de comprar una extensi√≥n que permitir√≠a a√±adir m√°s discos. De serie viene con 4GB de RAM ampliables a 8GB, aunque en alg√∫n foro he le√≠do que se le pueden meter 16GB (aunque esto est√° por comprobar). El procesador tiene 4 cores a 2.1GHz. Tiene una app store de aplicaciones que permite ampliar las funcionalidades del NAS y en caso de no encontrar alguna se podr√≠a usar Docker.\nContras:\n el precio 550-600‚Ç¨ el procesador no se puede cambiar, y la RAM s√≥lo se puede ampliar con garant√≠as hasta 8GB las aplicaciones para el m√≥vil no tienen muy buenas valoraciones lo veo justo tanto de procesador como de memoria RAM para las funcionalidades que quiero que ofrezca  DS1618+ Cumple con casi todos los requisitos, la √∫nica excepci√≥n es la ampliaci√≥n de recursos. Tiene 6 bah√≠as y la posibilidad de comprar una extensi√≥n que permitir√≠a a√±adir m√°s discos. De serie viene con 4GB de RAM ampliables a 32GB. El procesador tiene 4 cores a 2.1GHz. Tiene una app store de aplicaciones que permite ampliar las funcionalidades del NAS y en caso de no encontrar alguna se podr√≠a usar Docker.\nContras:\n el precio 750‚Ç¨ el procesador no se puede cambiar las aplicaciones para el m√≥vil no tienen muy buenas valoraciones lo veo justo de procesador para las funcionalidades que quiero que ofrezca  NAS DIY He estado investigado diferentes alternativas de SO orientados a montar un NAS, y he encontrado que el m√°s usado es FreeNas. Tambi√©n he encontrado otra alternativa que me gusta m√°s: unRaid.\nMuchas de las funcionalidades que quiero cubrir no son ofrecidas directamente por esos SOs, sino que hay que instalar algunos plugins/aplicaciones/contenedores para cubrirlas.\nFreeNas Est√° basado en FreeBSD y soporta el sistema de ficheros ZFS, que por lo que he le√≠do debe de ser muy bueno y solventa los inconvenientes de RAID.\nContras:\n al estar basado en FreeBSD no tiene soporte nativo de Docker muchas de las funcionalidades se cubren con aplicaciones/plugins que hay que buscar, instalar y configurar, con el esfuerzo que esto conlleva la existencia de aplicaciones m√≥viles para cubrir ciertos requisitos depende de las aplicaciones/plugins que se instalen  unRaid Es un SO basado en Debian, por lo que tiene soporte nativo de Docker. Como se puede deducir de su nombre, no soporta RAID. Lo que hace, es montar un array con todos los discos, dando la visi√≥n de que se trata de un √∫nico disco. Como mecanismo de protecci√≥n tiene un sistema de paridad que permitir√≠a el fallo de hasta 2 discos del sistema sin perder los datos. Los datos en los discos se almacenan como en un disco normal, de tal forma que si extraemos un disco del array y lo conectamos a otro dispositivo, podremos ver su contenido.\nContras:\n no es gratuito (pago √∫nico de 59-129‚Ç¨, dependiendo del n√∫mero de discos que se quieran usar) muchas de las funcionalidades se cubren con aplicaciones/plugins que hay que buscar, instalar y configurar, con el esfuerzo que esto conlleva la existencia de aplicaciones m√≥viles para cubrir ciertos requisitos depende de las aplicaciones/plugins que se instalen  Comparativa    Requisito Synology FreeNas unRaid     Tener backups de las Raspberry PI de forma peri√≥dica y autom√°tica üëç üëç 1 üëç 1   Tener sincronizados con el NAS algunos directorios tanto de equipos Windows como Linux üëç üëç 2 üëç 2   Tener las fotos/videos realizadas con dispositivos m√≥viles guardadas directamente en el NAS de forma autom√°tica üëç üëç 2 üëç 2   Tener forma de visualizar a trav√©s del m√≥vil las fotograf√≠as del NAS üëç üëç 2 3 üëç 2 3   Tener forma de visualizar a trav√©s del m√≥vil los documentos del NAS üëç üëç 2 üëç 2   Poder montar un volumen del NAS en cualquiera de los port√°tiles o PC para hacer un backup manual inicial de documentos o fotos üëç üëç üëç   Que el NAS haga de forma peri√≥dica un backup encriptado a alg√∫n cloud üëç üëç 1 üëç 1   Disponer de un cliente de descargas de BitTorrent y poder controlarlo a trav√©s del m√≥vil üëç üëç 4 üëç 5   Utilizar Plex Media Server como media center üëç üëç 4 üëç 5   A√±adir Radarr, Sonarr y Jackett (o CouchPotato) para el seguimiento de series y pel√≠culas y descargas automatizadas üëç ‚ùì üëç 5   Tener un repositorio de c√≥digo git üëç ‚ùì üëç 5   Poder editar documentos, hojas de c√°lculo, presentaciones, diagramas directamente a trav√©s del NAS üëç üëç 2 üëç 2   Aplicaci√≥n de mensajer√≠a privada üëç üëç 2 üëç 2   Aplicaci√≥n de notas privada üëç üëç 2 üëç 2   Aplicaci√≥n de calendario privada üëç üëç 2 üëç 2   Poder ampliar libremente los recursos del NAS en un futuro üëé üëç üëç   Poder ampliar libremente la funcionalidad del NAS üëç üëç 6 üëç 5    Conclusi√≥n Me da miedo de que me pase lo mismo que lo que me ha pasado con el QNAP: que me quede corto de recursos con el paso del tiempo y tener poco margen de maniobra. Se trata de dispositios con un coste elevado, como para tener que verse obligado a cambiarlo por el mero hecho de necesitar m√°s RAM (con la inversi√≥n de tiempo que hay que realizar para hacer el cambio).\nDecididamente voy a optar por un NAS DIY, y concretamente por uno con unRaid. He visto unos cuantos an√°lisis y videos de su funcionamiento y me ha gustado bastante. Creo que me convence m√°s la idea de array de discos que la de montar un RAID.\nAdem√°s que creo que con un mismo equipo puedo cubrir las 2 necesidades: disponer de un PC potente y tener un NAS con m√°s funcionalidades que el actual. En primer lugar comprar√© el PC que quer√≠a comprarme y le instalar√© unRaid. Sin me gusta como funciona, le har√© una ampliaci√≥n de hardware. Si por lo que fuera no quedo contento con el resultado, el equipo me vale como PC y volver√© a valorar qu√© hacer para el NAS.\nCuando haya elegido el hardware, montado el equipo, instalado y configurado unRaid, escribi√© otro post con la situaci√≥n final.\n  Usando Duplicati \u0026#x21a9;\u0026#xfe0e;\n Usando Nexcloud \u0026#x21a9;\u0026#xfe0e;\n Plex Media Server tambi√©n permite ver fotos, quiero ver si la gesti√≥n de √°lbumes es similar a google fotos o al menos mejor que la de Nexcloud \u0026#x21a9;\u0026#xfe0e;\n Seguro que se puede pero hay que buscar una aplicaci√≥n que permita hacerlo \u0026#x21a9;\u0026#xfe0e;\n Con alg√∫n contenedor Docker \u0026#x21a9;\u0026#xfe0e;\n Usando los Jail de FreeBSD (no tan extendido como los contenedores Docker) \u0026#x21a9;\u0026#xfe0e;\n   ","date":1580411760,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1580546460,"objectID":"85208c75b05a0a80995309e553ccb18a","permalink":"https://diegocastroviadero.com/post/como-quiero-organizar-mi-almacenamiento/","publishdate":"2020-01-30T19:16:00Z","relpermalink":"/post/como-quiero-organizar-mi-almacenamiento/","section":"post","summary":"Llevo ya un tiempo queriendo hacer una renovaci√≥n de los equipos que tengo y ya de paso reorganizar mi soluci√≥n para el almacenamiento. En este post plasmar√© c√≥mo me gustar√≠a reorganizarlo todo.","tags":["unRaid"],"title":"C√≥mo quiero organizar mi almacenamiento","type":"post"},{"authors":null,"categories":null,"content":"Prerequisitos  Tener un dominio en Google Domains Tener un repositorio en GitHub (ej: https://github.com/dicastro/dicastro.github.io)   Este repositorio no tiene por qu√© ser p√∫blico, en mi caso se trata de un repositorio privado.\n Pasos 1 - Activa GitHub Pages Para ello en la configuraci√≥n del repositorio de GitHub:\n Activa GitHub Pages seleccionando una rama desde la cu√°l se va a servir el contenido Configura un Custom Domain (ej: diegocastroviadero.com)  2 - Apunta el dominio (diegocastroviadero.com) a GitHub Pages Para ello en Google Domains:\n A√±ade un Custom resource record de tipo A apuntando a GitHub Pages     Nombre Tipo TTL Datos     @ A 1h 185.199.108.153   ¬† ¬† ¬† 185.199.109.153   ¬† ¬† ¬† 185.199.110.153   ¬† ¬† ¬† 185.199.111.153     En este caso @ hace referencia al propio dominio (diegocastroviadero.com)\n  Si las IPs anteriores se han quedado desfasadas, podr√°s encontrar los valores actualizados aqu√≠\n 3 - Apunta el subdominio www a GitHub Pages Para ello en Google Domains:\n A√±ade un Custom resource record de tipo CNAME apuntando a la url de GitHub Pages correspondiente al repositorio en cuesti√≥n (ej: dicastro.github.io)     Nombre Tipo TTL Datos     @ CNAME 1h dicastro.github.io    4 - Configura HTTPS Para ello en la configuraci√≥n del repositorio de GitHub:\n Fuerza el uso de HTTPS  Y en Google Domains:\n A√±ade un Custom resource record de tipo CAA permitiendo la emisi√≥n de certificados para el dominio (ej: diegocastroviadero.com) a la entidad emisora de certificados, que en el caso de GitHub es letsencrypt     Nombre Tipo TTL Datos     @ CAA 1h 0 issue \u0026ldquo;letsencrypt.org\u0026rdquo;     En este caso @ hace referencia al propio dominio (diegocastroviadero.com)\n  Para obtener el valor de la columna Datos de la entrada de tipo CAA se puede hacer uso de esta utilidad\n Referencias  https://www.techrepublic.com/article/how-to-add-a-certificate-authority-authorization-record-in-google-domains https://dev.to/trentyang/how-to-setup-google-domain-for-github-pages-1p58  ","date":1580236440,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1580323080,"objectID":"659a0889ce409b1da96f29f1d2c8f4c4","permalink":"https://diegocastroviadero.com/post/como-configurar-un-dominio-propio-de-google-domains-en-github-pages-y-con-https-activado/","publishdate":"2020-01-28T18:34:00Z","relpermalink":"/post/como-configurar-un-dominio-propio-de-google-domains-en-github-pages-y-con-https-activado/","section":"post","summary":"En este post se va a explicar c√≥mo configurar un dominio propio, comprado en Google Domains, en GitHub Pages y c√≥mo activar HTTPS","tags":["Google Domains","GitHub Pages","Let's encrypt"],"title":"C√≥mo configurar un dominio propio de Google Domains en GitHub Pages y con HTTPS activado","type":"post"},{"authors":null,"categories":null,"content":"Este es mi primer post de prueba.\nLa idea es utilizar este blog para escribir art√≠culos relacionados con algunos de mis intereses a modo de base de datos para posteriores consultas. Ser√°n art√≠culos sobre alg√∫n tema nuevo que est√© investigando o art√≠culos sobre c√≥mo resolver problemas a los que me haya enfrentado.\n","date":1576337940,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1576337940,"objectID":"664bde57003ea7f7bec74d75c0246ab3","permalink":"https://diegocastroviadero.com/post/hola-mundo/","publishdate":"2019-12-14T15:39:00Z","relpermalink":"/post/hola-mundo/","section":"post","summary":"Este es mi primer post","tags":null,"title":"Hola Mundo!","type":"post"},{"authors":null,"categories":null,"content":"Este proyecto ha sido realizado como trabajo final del m√°ster en Data Science \u0026amp; Big Data de la U-TAD.\nPara el desarrollo del proyecto se han realizado las siguientes tareas:\n Estudio del estado del arte en lo que a la detecci√≥n de objetos se refiere Desarrollo de una implementaci√≥n de YOLO V3 y de YOLO V3 Lite en python B√∫squeda y preparaci√≥n de un conjunto de im√°genes Entrenamiento de varios modelos YOLO con distintas configuraciones y realizaci√≥n de estudio comparativo de los resultados obtenidos Transformaci√≥n del modelo entrenado para ser explotado en un dispositivo m√≥vil Desarrollo de aplicaci√≥n android para la explotaci√≥n del modelo  El proyecto se compone de los siguientes repositorios:\n   Repositorio Descripci√≥n     \rtfm Contiene una implementaci√≥n en python de YOLO V3 y YOLO V3 Lite   \rtfm-android Contiene una aplicaci√≥n m√≥vil android para la explotaci√≥n del modelo entrenado mediante el uso de Tensor Flow Lite   \rtfm-doc Contiene la memoria del TFM    Referencias:\n Las im√°genes utilizadas para entrenar los modelos han sido obtenidas de kaggle La aplicaci√≥n m√≥vil se basa en un ejemplo de tensorflow lite La implementaci√≥n de YOLO V3 es un fork de este repositorio y la implementaci√≥n de YOLO V3 Lite est√° basada en este repositorio. Se han unificado ambas implementaciones en una √∫nica, se han a√±adido m√°s opciones de configuraci√≥n de los modelos y se soportan m√°s formatos de etiquetas de las im√°genes  ","date":1569715200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1569715200,"objectID":"d882fc2296783c8bc0aa60fe7de34f77","permalink":"https://diegocastroviadero.com/project/sistema-de-deteccion-automatica-de-baches-en-el-asfalto-a-partir-de-imagenes/","publishdate":"2019-09-29T00:00:00Z","relpermalink":"/project/sistema-de-deteccion-automatica-de-baches-en-el-asfalto-a-partir-de-imagenes/","section":"project","summary":"TFM del m√°ster en Data Science \u0026 Big Data de la U-TAD","tags":["Data Science","Deep Learning","YOLO"],"title":"Sistema de detecci√≥n autom√°tica de baches en el asfalto a partir de im√°genes","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"https://diegocastroviadero.com/cv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/cv/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"6880d30a4afb347490251c2f38986b57","permalink":"https://diegocastroviadero.com/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/posts/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":-62135596800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://diegocastroviadero.com/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]